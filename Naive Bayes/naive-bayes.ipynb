{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Bayes’ Theorem: Dining Safely\n",
    "99% of the restaurants in Kentish Town practice good hygiene. Each time you eat in a clean\n",
    "restaurant, there is a 1% chance that you will get sick, independent of your previous visits.\n",
    "Each time you eat in a restaurant that does not practice good hygiene, on the other hand,\n",
    "there is a 50% chance that you will get sick, independent of your previous visits.\n",
    "#### 1. You eat at a restaurant in Kentish Town and you get sick. What is the probability that the restaurant practices good hygiene?\n",
    "\n",
    "**Hint:** Using the law of total probability, first calculate the probability of the event ‘falling sick’. You can use this probability in your subsequent application of Bayes’ Theorem.\n",
    "\n",
    "**ANSWER**\n",
    "\n",
    "    P(restaurant clean) = 0.99\n",
    "    P(restaurant not clean) = 0.01\n",
    "    P(falling sick|restaurant clean) = 0.01\n",
    "    P(falling sick|restaurant not clean) = 0.50\n",
    "    \n",
    "    P(restaurant clean | falling sick)\n",
    "    = (P(falling sick|restaurant clean) * P(restaurant clean)) / P(falling sick)\n",
    "    = (P(falling sick|restaurant clean) * P(restaurant clean)) / ((P(falling sick|restaurant clean) * P(restaurant clean)) + (P(falling sick|restaurant not clean) * P(restaurant not clean)))\n",
    "    = (0.01 * 0.99) / ((0.01*0.99) + (0.50*0.01))\n",
    "    = 0.0099 / (0.0099 + 0.0050)\n",
    "    = 0.0099 / 0.0149\n",
    "    = 0.6644\n",
    "    = 66.44% chance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. You go to the same restaurant for a second time, and you get sick again. What is the probability of the restaurant practicing good hygiene now?\n",
    "\n",
    "**Hint:** Using the law of total probability, first calculate the probability of the event ‘falling sick twice’. In this calculation, you can use the conditional independences \n",
    "    \n",
    "    P(falling sick twice|restaurant clean) = P(falling sick once|restaurant clean)\n",
    "and\n",
    "    \n",
    "    P(falling sick twice|restaurant not clean) = P(falling sick once|restaurant not clean)\n",
    "    \n",
    "You can use these probabilities in your subsequent application of Bayes’ Theorem, where\n",
    "you can again use the same conditional independence.\n",
    "    \n",
    "**ANSWER:** Here we'll use restaurant clean probability calculated from previous stage:\n",
    "  \n",
    "    P(restaurant clean) = 0.99\n",
    "    P(restaurant not clean) = 0.01\n",
    "    P(falling sick|restaurant clean) = 0.01\n",
    "    P(falling sick|restaurant not clean) = 0.50\n",
    "    \n",
    "    \n",
    "    P(restaurant clean | falling sick twice)\n",
    "    = (P(falling sick twice|restaurant clean) * P(restaurant clean)) / P(falling sick twice)\n",
    "    = (P(falling sick twice|restaurant clean) * P(restaurant clean)) / ((P(falling sick twice|restaurant clean) * P(restaurant clean)) + (P(falling sick twice|restaurant not clean) * P(restaurant not clean)))\n",
    "    = (P(falling sick once|restaurant clean) * P(falling sick once|restaurant clean) * P(restaurant clean)) / ((P(falling sick once|restaurant clean) * P(falling sick once|restaurant clean) * P(restaurant clean)) + (P(falling sick once|restaurant not clean)* P(falling sick once|restaurant not clean) * P(restaurant not clean)))\n",
    "    = (0.01 * 0.01 * 0.99) / ((0.01 * 0.01 * 0.99) + (0.5 * 0.5 * 0.01))\n",
    "    = 0.000099 / (0.000099 +  0.0025)\n",
    "    = 0.0099 / 0.002599\n",
    "    = 0.03809\n",
    "    = 3.80% chance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Building a Spam Filter\n",
    "Consider the following 4 SMS messages and their classification as ‘ham’ or ‘spam’ messages:\n",
    "\n",
    "message | label\n",
    "--------|------\n",
    "I am not coming | ham\n",
    "Good work | ham\n",
    "Do you need viagra  | spam\n",
    "win an IMac | spam\n",
    "\n",
    "Using the above messages, construct a Na¨ıve Bayes classifier to classify new SMS messages. In particular:\n",
    "#### 1. Compute the prior probabilities of a new SMS message being ‘spam’ or ‘ham’. (These are just the empirical probabilities from the four messages above.) \n",
    "\n",
    "**ANSWER:** These are just intial probabilities of message being Spam / Ham which is 50% initially for both.\n",
    "\n",
    "Spam/Ham|Count/Freq|P(Spam/Ham)\n",
    "-|-|-\n",
    "Spam|2|2/4 = 0.5\n",
    "Ham|2|2/4 = 0.5\n",
    "-|-|-\n",
    "Total|4|100.00%\n",
    "\n",
    "\n",
    "#### 2. For each de-capitalised keyword that appears in your training set (that is, ‘i’, ‘am’, ‘not’, ‘coming’, ‘good’, ‘work’, ‘do’, ‘you’, ‘need’, ‘viagra’, ‘win’, ‘an’ and ‘imac’), build a frequency table that records the likelihoods P(W|ham), P(¬W|ham), P(W|spam) and P(¬W|spam)\n",
    "\n",
    "**ANSWER:**\n",
    "\n",
    "Word|Count/Freq|Spam|Ham|P(W - Spam)|P(W - Ham)|P(~W - Spam)|P(~W - Ham)\n",
    "-|-|-|-|-|-|-|-\n",
    "i|1|0|1|0 = 0.05|1/6 = 0.166|1 -  0.05 = 0.95|1 -  0.166= 0.833\n",
    "am|1|0|1|0 = 0.05|1/6 = 0.166|1 -  0.05 = 0.95|1 -  0.166= 0.833\n",
    "not|1|0|1|0 = 0.05|1/6 = 0.166|1 -  0.05 = 0.95|1 -  0.166= 0.833\n",
    "coming|1|0|1|0 = 0.05|1/6 = 0.166|1 -  0.05 = 0.95|1 -  0.166= 0.833\n",
    "good|1|0|1|0 = 0.05|1/6 = 0.166|1 -  0.05 = 0.95|1 -  0.166= 0.833\n",
    "work|1|0|1|0 = 0.05|1/6 = 0.166|1 -  0.05 = 0.95|1 -  0.166= 0.833\n",
    "do|1|1|0|1/7 = 0.142|0 = 0.05|1 -  0.142 = 0.858|1 -  0.05 = 0.95\n",
    "you|1|1|0|1/7 = 0.142|0 = 0.05|1 -  0.142 = 0.858|1 -  0.05 = 0.95\n",
    "need|1|1|0|1/7 = 0.142|0 = 0.05|1 -  0.142 = 0.858|1 -  0.05 = 0.95\n",
    "viagra|1|1|0|1/7 = 0.142|0 = 0.05|1 -  0.142 = 0.858|1 -  0.05 = 0.95\n",
    "win|1|1|0|1/7 = 0.142|0 = 0.05|1 -  0.142 = 0.858|1 -  0.05 = 0.95\n",
    "an|1|1|0|1/7 = 0.142|0 = 0.05|1 -  0.142 = 0.858|1 -  0.05 = 0.95\n",
    "imac|1|1|0|1/7 = 0.142|0 = 0.05|1 -  0.142 = 0.858|1 -  0.05 = 0.95\n",
    "-|-|-|-|-|-|-|-\n",
    "Total|12|7|5|100.00%|100.00%\n",
    "\n",
    "\n",
    "Now you can use the Na¨ıve Bayes algorithm to make predictions. Predict if the following two SMS messages are ham or spam:\n",
    "\n",
    "message | label\n",
    "--------|------\n",
    "Coming home | ?\n",
    "Get Viagra now | ?\n",
    "\n",
    "**ANSWER**\n",
    "\n",
    "We have above maintained small dictionary of words which appeared in messages when we trained our model. If we found that words in new upcoming messages then based on above probability tables we make prediction of new mail being spam/ham.\n",
    "\n",
    "Prior Probabilites of message beng spam/ham is : `P(Spam) = 0.5` & `P(Ham) = 0.5`\n",
    "    \n",
    "**Message 1:** Coming home\n",
    "\n",
    "Here only word `coming` appears in our words dictionary which we are maintaining above. Hence we'll make prediction based on this word appearing in message and whether it's spam/ham mail based on that.\n",
    "    \n",
    "    P(spam|¬i ∧ ¬am ∧ ¬not ∧ coming ∧ ¬good ∧ ¬work ∧ ¬do ∧ ¬you ∧ ¬need ∧ ¬viagra ∧ ¬win ∧ ¬an ∧ ¬imac)\n",
    "    ∝  P(spam)*P(¬i|spam)*P(¬am|spam)*P(¬not|spam)*P(coming|spam)*P(¬good|spam)*P(¬work|spam)*P(¬do|spam)*P(¬you|spam)*\n",
    "    P(¬need|spam)*P(¬viagra|spam)*P(¬win|spam)*P(¬an|spam)*P(¬imac|spam)\n",
    "    ∝ 0.50 * 0.95 * 0.95 * 0.95 * 0.05 * 0.95 * 0.95 * 0.858 * 0.858 * 0.858 * 0.858 * 0.858 * 0.858 * 0.858\n",
    "    ∝ 0.006621\n",
    "    \n",
    "    P(ham|¬i ∧ ¬am ∧ ¬not ∧ coming ∧ ¬good ∧ ¬work ∧ ¬do ∧ ¬you ∧ ¬need ∧ ¬viagra ∧ ¬win ∧ ¬an ∧ ¬imac)\n",
    "    ∝ P(ham)*P(¬i|ham)*P(¬am|ham)*P(¬not|ham)*P(coming|ham)*P(¬good|ham)*P(¬work|ham)*P(¬do|ham)*P(¬you|ham)*\n",
    "    P(¬need|ham)*P(¬viagra|ham)*P(¬win|ham)*P(¬an|ham)*P(¬imac|ham)\n",
    "    ∝ 0.50 * 0.833 * 0.833 * 0.833 * 0.166 * 0.833 * 0.833 * 0.95 * 0.95 * 0.95 * 0.95 * 0.95 * 0.95 * 0.95\n",
    "    ∝ 0.02790\n",
    "    \n",
    "We have now got near values for message being spam/ham. We'll now use normalization to convert them to probabilities (P(spam) + P(ham) = 1).\n",
    "    \n",
    "    p(spam) = 0.006621 / (0.00621 + 0.02790) = 0.006621 / 0.034521 = 0.1917\n",
    "    p(ham)  = 0.02790  / (0.00621 + 0.02790) = 0.027900 / 0.034521 = 0.8082\n",
    "    \n",
    "**Message 2:** Get Viagra now\n",
    "\n",
    "Here only word `viagra` appears in our words dictionary which we are maintaining above. Hence we'll make prediction based on this word appearing in message and whether it's spam/ham mail based on that.\n",
    "    \n",
    "    P(spam|¬i ∧ ¬am ∧ ¬not ∧ ¬coming ∧ ¬good ∧ ¬work ∧ ¬do ∧ ¬you ∧ ¬need ∧ viagra ∧ ¬win ∧ ¬an ∧ ¬imac)\n",
    "    ∝  P(spam)*P(¬i|spam)*P(¬am|spam)*P(¬not|spam)*P(¬coming|spam)*P(¬good|spam)*P(¬work|spam)*P(¬do|spam)*P(¬you|spam)*\n",
    "    P(¬need|spam)*P(viagra|spam)*P(¬win|spam)*P(¬an|spam)*P(¬imac|spam)\n",
    "    ∝ 0.50 * 0.95 * 0.95 * 0.95 * 0.95 * 0.95 * 0.95 * 0.858 * 0.858 * 0.858 * 0.142 * 0.858 * 0.858 * 0.858\n",
    "    ∝ 0.0208\n",
    "    \n",
    "    P(ham|¬i ∧ ¬am ∧ ¬not ∧ ¬coming ∧ ¬good ∧ ¬work ∧ ¬do ∧ ¬you ∧ ¬need ∧ viagra ∧ ¬win ∧ ¬an ∧ ¬imac)\n",
    "    ∝ P(ham)*P(¬i|ham)*P(¬am|ham)*P(¬not|ham)*P(¬coming|ham)*P(¬good|ham)*P(¬work|ham)*P(¬do|ham)*P(¬you|ham)*\n",
    "    P(¬need|ham)*P(viagra|ham)*P(¬win|ham)*P(¬an|ham)*P(¬imac|ham)\n",
    "    ∝ 0.50 * 0.833 * 0.833 * 0.833 * 0.833 * 0.833 * 0.833 * 0.95 * 0.95 * 0.95 * 0.05 * 0.95 * 0.95 * 0.95\n",
    "    ∝ 0.00613\n",
    "    \n",
    "We have now got near values for message being spam/ham. We'll now use normalization to convert them to probabilities (P(spam) + P(ham) = 1).\n",
    "    \n",
    "    p(spam) = 0.02080 / (0.0208 + 0.00613) = 0.02080 / 0.02693 = 0.7723\n",
    "    p(ham)  = 0.00613 / (0.0208 + 0.00613) = 0.00613 / 0.02693 = 0.2276\n",
    "\n",
    "**Hint**\n",
    "This actually turns out to be more cumbersome than expected: For the first SMS message, for\n",
    "example, you need to use the law of total probability as well as the conditional independence\n",
    "to compute the quantity\n",
    "\n",
    "    P(¬i ∧ ¬am ∧ ¬not ∧ coming ∧ ¬good ∧ ¬work ∧ ¬do ∧ ¬you ∧ ¬need ∧ ¬viagra ∧ ¬win ∧ ¬an ∧ ¬imac).\n",
    "\n",
    "Afterwards you can compute the quantities\n",
    "    \n",
    "    P(ham|¬i ∧ ¬am ∧ ¬not ∧ coming ∧ ¬good ∧ ¬work ∧ ¬do ∧ ¬you ∧ ¬need ∧ ¬viagra ∧ ¬win ∧ ¬an ∧ ¬imac)\n",
    "    \n",
    "and\n",
    "\n",
    "    P(spam|¬i ∧ ¬am ∧ ¬not ∧ coming ∧ ¬good ∧ ¬work ∧ ¬do ∧ ¬you ∧ ¬need ∧ ¬viagra ∧ ¬win ∧ ¬an ∧ ¬imac)\n",
    "\n",
    "using Bayes’ Theorem and the conditional independence.\n",
    "\n",
    "Alternatively, you can exploit (as explained in the slides) the fact that\n",
    "\n",
    "    P(ham|¬i ∧ ¬am ∧ . . .) ∝ P(ham) · P(¬i|ham) · P(¬am|ham) · . . .\n",
    "and\n",
    "\n",
    "    P(spam|¬i ∧ ¬am ∧ . . .) ∝ P(spam) · P(¬i|spam) · P(¬am|spam) · . . .\n",
    "\n",
    "to calculate propensities that you subsequently scale to probabilities by dividing them with\n",
    "the sum\n",
    "\n",
    "    P(ham) · P(¬i|ham) · P(¬am|ham) · . . . + P(spam) · P(¬i|spam) · P(¬am|spam) · . . .\n",
    "\n",
    "You can use a spreadsheet to simplify computations if you wish. Make sure that you\n",
    "explain every step, though!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readme  SMSSpamCollection\r\n"
     ]
    }
   ],
   "source": [
    "%ls smsspamcollection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Assignment #2\n",
    "For this group assignment, download the SMS Spam Collection data set from\n",
    "    \n",
    "    https://archive.ics.uci.edu/ml/machine-learning-databases/00228/\n",
    "\n",
    "and follow the steps below to build a Na ̈ıve Bayes spam filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cat smsspamcollection/SMSSpamCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load the data into a Python data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spam/Ham</th>\n",
       "      <th>Mail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Spam/Ham                                               Mail\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('smsspamcollection/SMSSpamCollection', names = ['Spam/Ham','Mail'], sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Pre-process the SMS messages: Remove all punctuation and numbers from the SMS messages, and change all messages to lower case. (Please provide the Python code that achieves this!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spam/Ham</th>\n",
       "      <th>Mail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Spam/Ham                                               Mail\n",
       "0      ham  go until jurong point, crazy.. available only ...\n",
       "1      ham                      ok lar... joking wif u oni...\n",
       "2     spam  free entry in 2 a wkly comp to win fa cup fina...\n",
       "3      ham  u dun say so early hor... u c already then say...\n",
       "4      ham  nah i don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Mail'] = [mail.lower() for mail in df['Mail']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spam/Ham</th>\n",
       "      <th>Mail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in a wkly comp to win fa cup final ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i don t think he goes to usf he lives arou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Spam/Ham                                               Mail\n",
       "0      ham  go until jurong point crazy available only in ...\n",
       "1      ham                            ok lar joking wif u oni\n",
       "2     spam  free entry in a wkly comp to win fa cup final ...\n",
       "3      ham        u dun say so early hor u c already then say\n",
       "4      ham  nah i don t think he goes to usf he lives arou..."
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex = re.compile(r'[a-z]+')\n",
    "df['Mail'] = [' '.join(regex.findall(mail)) for mail in df['Mail']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "(5572,)\n",
      "[3237  843 3521 2123  738  923 2977 4623 4388 4931]\n",
      "(5572,)\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(len(df))\n",
    "print(x[:10])\n",
    "print(x.shape)\n",
    "rand = np.random.RandomState(123)\n",
    "rand.shuffle(x)\n",
    "print(x[:10])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spam/Ham</th>\n",
       "      <th>Mail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3237</th>\n",
       "      <td>ham</td>\n",
       "      <td>aight text me when you re back at mu and i ll ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>ham</td>\n",
       "      <td>our prashanthettan s mother passed away last n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3521</th>\n",
       "      <td>ham</td>\n",
       "      <td>no it will reach by only she telling she will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>ham</td>\n",
       "      <td>do you know when the result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>spam</td>\n",
       "      <td>hi customer loyalty offer the new nokia mobile...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Spam/Ham                                               Mail\n",
       "3237      ham  aight text me when you re back at mu and i ll ...\n",
       "843       ham  our prashanthettan s mother passed away last n...\n",
       "3521      ham  no it will reach by only she telling she will ...\n",
       "2123      ham                        do you know when the result\n",
       "738      spam  hi customer loyalty offer the new nokia mobile..."
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[x]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Shuffle the messages and split them into a training set (2,500 messages), a validation set (1,000 messages) and a test set (all remaining messages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2500,), (2500,), (1000,), (1000,), (2072,), (2072,))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(df['Mail'].values, df['Spam/Ham'].values, \n",
    "                                                                   train_size=2500, test_size = len(df) - 2500,\n",
    "                                                                   stratify= df['Spam/Ham'].values)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val,Y_val, \n",
    "                                                train_size = 1000, test_size = len(Y_val) - 1000,\n",
    "                                                stratify=Y_val)\n",
    "X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({'ham': 4825, 'spam': 747}),\n",
       " Counter({'ham': 2165, 'spam': 335}),\n",
       " Counter({'spam': 134, 'ham': 866}),\n",
       " Counter({'ham': 1794, 'spam': 278}))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(df['Spam/Ham'].values), collections.Counter(Y_train), collections.Counter(Y_val), collections.Counter(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. While Python’s SciKit-Learn library has a Na ̈ıve Bayes classifier, it works with continuous probability distributions and assumes numerical features. Although it is possible to transform categorical variables into numerical features using a binary encoding, we will instead build a simple Na ̈ıve Bayes classifier from scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesForSpam :\n",
    "    def train(self , hamMessages , spamMessages ) :\n",
    "        self.words = set(' '.join(hamMessages + spamMessages).split())\n",
    "        self.priors = np.zeros(2)\n",
    "        self.priors[0] = float(len(hamMessages)) / (len(hamMessages) +  len(spamMessages))\n",
    "        self.priors[1] = 1.0 - self.priors[0]\n",
    "        self.likelihoods = []\n",
    "        for i,w in enumerate(self.words):\n",
    "            prob1 = (1.0 + len([m for m in hamMessages if w in m])) / len(hamMessages)\n",
    "            prob2 = (1.0 + len( [m for m in spamMessages if w in m])) / len(spamMessages)\n",
    "            self.likelihoods.append([min(prob1, 0.95) , min(prob2 , 0.95)])\n",
    "        self.likelihoods = np.array(self.likelihoods).T\n",
    "            \n",
    "    def train2(self,hamMessages,spamMessages, times=20):\n",
    "        self.words = set(' '.join(hamMessages + spamMessages).split())\n",
    "        self.priors = np.zeros(2)\n",
    "        self.priors[0] = float(len(hamMessages)) / (len(hamMessages) + len(spamMessages))\n",
    "        self.priors[1] = 1.0 - self.priors[0]\n",
    "        self.likelihoods = []\n",
    "        spamkeywords = []\n",
    "        for i,w in enumerate(self.words):\n",
    "            prob1 = (1.0 + len([m for m in hamMessages if w in m])) / len(hamMessages)\n",
    "            prob2 = (1.0 + len([m for m in spamMessages if w in m])) / len(spamMessages)\n",
    "            if prob1 * times < prob2 :\n",
    "                self.likelihoods.append([min(prob1 , 0.95) , min(prob2 , 0.95)])\n",
    "                spamkeywords.append(w)\n",
    "        self.words = spamkeywords\n",
    "        self.likelihoods = np.array(self.likelihoods).T\n",
    "\n",
    "    def predict(self , message):\n",
    "        posteriors = np.copy(self.priors)\n",
    "        for i,w in enumerate(self.words):\n",
    "            if w in message.lower() : #convert to lower−case\n",
    "                posteriors *= self.likelihoods[:,i]\n",
    "            else:\n",
    "                posteriors *= np.ones(2) - self.likelihoods[:,i]\n",
    "            posteriors = posteriors / np.linalg.norm(posteriors , ord = 1) # normalise\n",
    "        if posteriors[0] > 0.5:\n",
    "            return ['ham', posteriors[0]]\n",
    "        return ['spam ', posteriors[1]]\n",
    "    \n",
    "    def score(self,messages,labels):\n",
    "        confusion = np.zeros(4).reshape(2,2)\n",
    "        for m,l in zip(messages,labels):\n",
    "            if self.predict(m)[0] == 'ham' and l == 'ham':\n",
    "                confusion[0,0] += 1\n",
    "            elif self.predict(m)[0] == 'ham' and l == 'spam':\n",
    "                confusion[0,1] += 1\n",
    "            elif self.predict(m)[0] == 'spam' and l == 'ham':\n",
    "                confusion[1,0] += 1\n",
    "            elif self.predict(m)[0] == 'spam' and l == 'spam':\n",
    "                confusion[1,1] += 1\n",
    "        return (confusion[0,0] + confusion[1,1])/float(confusion.sum()) , confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Explain the code: What is the purpose of each function? What do ’train’ and ‘train2’ do, and what is the difference between them? Where in the code is Bayes’ Theorem being applied?\n",
    "\n",
    "We have defined class named `NaiveBayesForSpam` which holds 4 methods `(train, train2, predict, score)`.\n",
    "\n",
    "* `train()` - It takes 2 arguments as input. First argument is list of ham messages and second argument is list of spam messages. When this method is called it loops through each of the word of ham and spam messages and creates likelihood for each word. It maintains probability for each word which will be how much it contributes to prediction(spam/ham) if that word occurs in message.It also maintains prior probabilities as well for spam and ham messages which is how much percentage of total mails as spam and how much are ham.\n",
    "* `train2()` - It takes 2 arguments as input. First argument is list of ham messages and second argument is list of spam messages. When this method is called it loops through each of the word of ham and spam messages and creates likelihood for only word where probability of word in spam mail is being high. Its only maintaining words which are commonly occuring in spam messages than maintaining list of all words from ham messages as well. It maintains probability for each word which will be how much it contributes to prediction(spam/ham) if that word occurs in message. It also maintains prior probabilities as well for spam and ham messages which is how much percentage of total mails as spam and how much are ham.\n",
    "* `predict()` - It takes as input message to be classified as spam/ham. This method loops through all words maintained during training and using Naive Bayes predicts probability of messsage being spam/ham. It returns list where first string is spam/ham and second value of list is probability of it being spam/ham.\n",
    "* `score()` - It takes as input 2 arguments. First argument is list of messages and 2nd argument is actual labels(spam/ham) for each message. It loops through each messages and predicts whether it's spam/ham using `predict()` method. It also maintains confusion matrix using actual lables provided as input. It then calculates accuracy of model on list of messages provided as input. It returns accuracy of model on list of messages and confusion matrix as list.\n",
    "\n",
    "Confusion Matrix = \n",
    "\n",
    "                    [[TP, FN],\n",
    "                    [FP, TN]]\n",
    "\n",
    "`predict()` method has actual implementation of NaiveBayes theorem where we are using likelihoods calculated during training and based on that getting near values for message being spam/ham. Using this near values, we calculate probabilities using normalisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Use your training set to train the classifiers ‘train’ and ‘train2’. Note that the interfaces of our classifiers require you to pass the ham and spam messages separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words :  5131\n",
      "First Few Words :  ['samantha', 'unfortunately', 'senses', 'another', 'indians', 'praveesh', 'anyway', 'triumphed', 'understood', 'their']\n",
      "CPU times: user 2.56 s, sys: 0 ns, total: 2.56 s\n",
      "Wall time: 2.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "naive_bayes_classifier = NaiveBayesForSpam()\n",
    "naive_bayes_classifier.train(X_train[Y_train == 'ham'].tolist(), X_train[Y_train == 'spam'].tolist())\n",
    "print('Total Words : ', len(naive_bayes_classifier.words))\n",
    "print('First Few Words : ',list(naive_bayes_classifier.words)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words :  204\n",
      "First Few Words :  ['statement', 'freefone', 'order', 'services', 'pod', 'ae', 'truly', 'motorola', 'orange', 'bluetooth']\n",
      "CPU times: user 2.56 s, sys: 0 ns, total: 2.56 s\n",
      "Wall time: 2.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "naive_bayes_classifier2 = NaiveBayesForSpam()\n",
    "naive_bayes_classifier2.train2(X_train[Y_train == 'ham'].tolist(), X_train[Y_train == 'spam'].tolist())\n",
    "print('Total Words : ', len(naive_bayes_classifier2.words))\n",
    "print('First Few Words : ',list(naive_bayes_classifier2.words)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words :  793\n",
      "First Few Words :  ['customers', 'statement', 'marley', 'calls', 'freefone', 'java', 'order', 'services', 'pod', 'doubletxt']\n",
      "CPU times: user 2.97 s, sys: 0 ns, total: 2.97 s\n",
      "Wall time: 2.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "naive_bayes_classifier3 = NaiveBayesForSpam()\n",
    "naive_bayes_classifier3.train2(X_train[Y_train == 'ham'].tolist(), X_train[Y_train == 'spam'].tolist(), 10) ##Notice times parameter\n",
    "print('Total Words : ', len(naive_bayes_classifier3.words))\n",
    "print('First Few Words : ',list(naive_bayes_classifier3.words)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words :  186\n",
      "First Few Words :  ['statement', 'freefone', 'services', 'pod', 'ae', 'truly', 'motorola', 'orange', 'bluetooth', 'discount']\n",
      "CPU times: user 2.54 s, sys: 0 ns, total: 2.54 s\n",
      "Wall time: 2.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "naive_bayes_classifier4 = NaiveBayesForSpam()\n",
    "naive_bayes_classifier4.train2(X_train[Y_train == 'ham'].tolist(), X_train[Y_train == 'spam'].tolist(), 25) ##Notice times parameter\n",
    "print('Total Words : ', len(naive_bayes_classifier4.words))\n",
    "print('First Few Words : ',list(naive_bayes_classifier4.words)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Using the validation set, explore how each of the two classifiers performs out of sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 9s, sys: 111 ms, total: 9min 9s\n",
      "Wall time: 9min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accuracy_val1, confusion_mat_val1 = naive_bayes_classifier.score(X_val.tolist(), Y_val.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy :  0.9803012746234068\n",
      "Confusion Matrix : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[846.,  17.],\n",
       "       [  0.,   0.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Validation Accuracy : ',accuracy_val1)\n",
    "print('Confusion Matrix : ')\n",
    "confusion_mat_val1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.8 s, sys: 0 ns, total: 20.8 s\n",
      "Wall time: 20.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accuracy_val2, confusion_mat_val2 = naive_bayes_classifier2.score(X_val.tolist(), Y_val.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy :  0.9706214689265537\n",
      "Confusion Matrix : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[859.,  26.],\n",
       "       [  0.,   0.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Validation Accuracy : ',accuracy_val2)\n",
    "print('Confusion Matrix : ')\n",
    "confusion_mat_val2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 19s, sys: 4 ms, total: 1min 19s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accuracy_val3, confusion_mat_val3 = naive_bayes_classifier3.score(X_val.tolist(), Y_val.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy :  0.9707865168539326\n",
      "Confusion Matrix : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[864.,  26.],\n",
       "       [  0.,   0.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Validation Accuracy : ',accuracy_val3)\n",
    "print('Confusion Matrix : ')\n",
    "confusion_mat_val3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.9 s, sys: 4 ms, total: 18.9 s\n",
      "Wall time: 18.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accuracy_val4, confusion_mat_val4 = naive_bayes_classifier4.score(X_val.tolist(), Y_val.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy :  0.971655328798186\n",
      "Confusion Matrix : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[857.,  25.],\n",
       "       [  0.,   0.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Validation Accuracy : ',accuracy_val4)\n",
    "print('Confusion Matrix : ')\n",
    "confusion_mat_val4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Why is the ‘train2’ classifier faster? Why does it yield a better accuracy both on the training and the validation set?\n",
    "As a part of `train2()` method, we are only maintaining words which are part of spam messages and contribute to message being spam with high probability. Words getting maintained as part of classified trained using this methods will be less compared to `train()`. Using these words we can guess with high probability of message being spam. Also its better to keep message as ham if model is less sure about message being spam. This way important mail won't end up in spam folder if classifier is less confident about message being spam like around 0.6-0.7 probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. How many false positives (ham messages classified as spam messages) did you get in your validation set? How would you change the code to reduce false positives at the expense of possibly having more false negatives (spam messages classified as ham messages)?\n",
    "\n",
    "We are getting 0 false positives(ham messages getting classified as spam messages). All messages are getting classified as ham due to high majority of ham messages and model overfitting.\n",
    "\n",
    "We can modify `if` statement in `train2()` method to change proportion of comparision between `prob1` & `prob2`. We have modified code above to pass one extra argument to `train2()` method. We have above created 2 another model with values more and less then default 20 times. Using more values for parameter `times` values results in taking only those words for which our model is more sure to be part of spam messages. More value for parameter spam will result in having more false negatives and less false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Run the ‘train2’ classifier on the test set and report its performance using a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43 s, sys: 0 ns, total: 43 s\n",
      "Wall time: 43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accuracy_test2, confusion_mat_test2 = naive_bayes_classifier2.score(X_test.tolist(), Y_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy :  0.9747668678003292\n",
      "Confusion Matrix : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1777.,   46.],\n",
       "       [   0.,    0.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Test Accuracy : ',accuracy_test2)\n",
    "print('Confusion Matrix : ')\n",
    "confusion_mat_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 45s, sys: 7.99 ms, total: 2min 45s\n",
      "Wall time: 2min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accuracy_test3, confusion_mat_test3 = naive_bayes_classifier3.score(X_test.tolist(), Y_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy :  0.9781540141998908\n",
      "Confusion Matrix : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1791.,   40.],\n",
       "       [   0.,    0.]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Test Accuracy : ',accuracy_test3)\n",
    "print('Confusion Matrix : ')\n",
    "confusion_mat_test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.1 s, sys: 3.99 ms, total: 39.1 s\n",
      "Wall time: 39.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accuracy_test4, confusion_mat_test4 = naive_bayes_classifier4.score(X_test.tolist(), Y_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy :  0.9726177437020811\n",
      "Confusion Matrix : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1776.,   50.],\n",
       "       [   0.,    0.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Test Accuracy : ',accuracy_test4)\n",
    "print('Confusion Matrix : ')\n",
    "confusion_mat_test4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
