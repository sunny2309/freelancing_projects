{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise\n",
    "from surprise import BaselineOnly, Dataset, KNNBasic, KNNBaseline, NormalPredictor, SVD, SlopeOne, NMF, SVDpp, KNNWithMeans, KNNWithZScore, CoClustering\n",
    "from surprise import accuracy, evaluate, Reader, model_selection\n",
    "import utils\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, log_loss\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mAbstractBaseCollabFilterSGD.py\u001b[0m*    \u001b[01;34mmodel_params\u001b[0m/\r\n",
      "\u001b[01;32mCollabFilterMeanOnly.py\u001b[0m*           \u001b[01;34mplots\u001b[0m/\r\n",
      "\u001b[01;32mCollabFilterMeanOnly.py~\u001b[0m*          Project systems updated.pdf\r\n",
      "\u001b[01;32mCollabFilterOneScalarPerItem.py\u001b[0m*   \u001b[01;34m__pycache__\u001b[0m/\r\n",
      "\u001b[01;32mCollabFilterOneScalarPerItem.py~\u001b[0m*  recommendation.ipynb\r\n",
      "\u001b[01;32mCollabFilterOneVectorPerItem.py\u001b[0m*   \u001b[01;32mrequirements.txt\u001b[0m*\r\n",
      "\u001b[01;32mCollabFilterOneVectorPerItem.py~\u001b[0m*  \u001b[01;34mselect_movies\u001b[0m/\r\n",
      "\u001b[01;34mdata_movie_lens_100k\u001b[0m/              \u001b[01;34mtest_preds\u001b[0m/\r\n",
      "\u001b[01;32mIntroduction_Autograd.ipynb\u001b[0m*       \u001b[01;32mutils.py\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Simple Baseline Model with SGD and autograd\n",
    "As a part of this model, we are guessing constant rating for each of user and movie id combinations. We'll be predicting same value for each combinations. We'll try to find out optimal value of this prediction $\\mu$ so that Mean Absolute Error is less as much as possible.\n",
    "\n",
    "#### Epochs vs MAE for train & validation sets\n",
    "<img src='plots/M1.png' style='width:600px;height:600px;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regularization:** Adding regularization is not helping much to improve performance. We tried adding L2 regularization based on parameter $\\mu$.\n",
    "\n",
    "**Performance Without adding reguarization:**\n",
    "\n",
    "* Train MAE : `0.941`\n",
    "* Validation MAE : `0.943`\n",
    "\n",
    "**Performance adding L2 reguarization:**\n",
    "\n",
    "* Train MAE : `0.941`\n",
    "* Validation MAE : `0.943`\n",
    "\n",
    "**Best Score $\\mu$ :** `3.54`\n",
    "\n",
    "**Clsoed Form Solution :** One can also take `mean` of trainset ratings and guess it as rating for each test set combinations. It won't require to use SGD at all. Average rating on train set is `3.53` which matches with results of SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 : One Scaler Per Item Baseline with SGD and autograd\n",
    "We are using one scaler per user and one scaler per movie for this model. We then optimize this scalers for each movie and user through training and evaluating as MAE.\n",
    "\n",
    "#### Epochs vs MAE for train and validation set\n",
    "<img src='plots/M2.png' style='width:600px;height:600px;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`M2` model is quite an improvement in terms of performance from `M1` model as it guesses different ratings for each `(user_id, movie_id)` combinations whereas `M1` guesses same rating for each combinations.\n",
    "\n",
    "* Train MAE : `0.727`\n",
    "* Validation MAE : `0.744`\n",
    "\n",
    "**Best Params** : Please refer to file `M2.json` under folder `model_params` for getting idea about model's trained parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Movies Examination\n",
    "We have saved `c_per_item` parameter for selected set of movies saved in `select_movies.csv` file.\n",
    "\n",
    "We have noticed that `Animation/Cartoon/Horror` movies (Toy Story, Lion King, Scream etc) has very `negative` values for parameter `c` whereas `scifi/adventure` movies (Empire Strikes Back, Snow White and Seven Dwarves) has quite `high` values for paramer `c`. Romantic comedy movie like Sleepless in Seattle (1993)\talso has quite high value for parameter `c`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>release_year</th>\n",
       "      <th>orig_item_id</th>\n",
       "      <th>c_parameter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.017818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>Lion King, The (1994)</td>\n",
       "      <td>1994</td>\n",
       "      <td>71</td>\n",
       "      <td>-0.083676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98</td>\n",
       "      <td>Snow White and the Seven Dwarfs (1937)</td>\n",
       "      <td>1937</td>\n",
       "      <td>99</td>\n",
       "      <td>0.807818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131</td>\n",
       "      <td>Wizard of Oz, The (1939)</td>\n",
       "      <td>1939</td>\n",
       "      <td>132</td>\n",
       "      <td>0.501377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142</td>\n",
       "      <td>Sound of Music, The (1965)</td>\n",
       "      <td>1965</td>\n",
       "      <td>143</td>\n",
       "      <td>0.565982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>49</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "      <td>1977</td>\n",
       "      <td>50</td>\n",
       "      <td>0.086464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>171</td>\n",
       "      <td>Empire Strikes Back, The (1980)</td>\n",
       "      <td>1980</td>\n",
       "      <td>172</td>\n",
       "      <td>0.832206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>180</td>\n",
       "      <td>Return of the Jedi (1983)</td>\n",
       "      <td>1997</td>\n",
       "      <td>181</td>\n",
       "      <td>0.615166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>81</td>\n",
       "      <td>Jurassic Park (1993)</td>\n",
       "      <td>1993</td>\n",
       "      <td>82</td>\n",
       "      <td>0.704766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>251</td>\n",
       "      <td>Lost World: Jurassic Park, The (1997)</td>\n",
       "      <td>1997</td>\n",
       "      <td>252</td>\n",
       "      <td>0.153030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>173</td>\n",
       "      <td>Raiders of the Lost Ark (1981)</td>\n",
       "      <td>1981</td>\n",
       "      <td>174</td>\n",
       "      <td>0.561762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>209</td>\n",
       "      <td>Indiana Jones and the Last Crusade (1989)</td>\n",
       "      <td>1989</td>\n",
       "      <td>210</td>\n",
       "      <td>0.619021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>65</td>\n",
       "      <td>While You Were Sleeping (1995)</td>\n",
       "      <td>1995</td>\n",
       "      <td>66</td>\n",
       "      <td>-0.240191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>87</td>\n",
       "      <td>Sleepless in Seattle (1993)</td>\n",
       "      <td>1993</td>\n",
       "      <td>88</td>\n",
       "      <td>0.801698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>254</td>\n",
       "      <td>My Best Friend's Wedding (1997)</td>\n",
       "      <td>1997</td>\n",
       "      <td>255</td>\n",
       "      <td>0.280272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>90</td>\n",
       "      <td>Nightmare Before Christmas, The (1993)</td>\n",
       "      <td>1993</td>\n",
       "      <td>91</td>\n",
       "      <td>0.252342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>199</td>\n",
       "      <td>Shining, The (1980)</td>\n",
       "      <td>1980</td>\n",
       "      <td>200</td>\n",
       "      <td>0.197453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>218</td>\n",
       "      <td>Nightmare on Elm Street, A (1984)</td>\n",
       "      <td>1984</td>\n",
       "      <td>219</td>\n",
       "      <td>-0.018336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>286</td>\n",
       "      <td>Scream (1996)</td>\n",
       "      <td>1996</td>\n",
       "      <td>288</td>\n",
       "      <td>-0.134032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>893</td>\n",
       "      <td>Scream 2 (1997)</td>\n",
       "      <td>1997</td>\n",
       "      <td>895</td>\n",
       "      <td>-0.083332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    item_id                                      title  release_year  \\\n",
       "0         0                           Toy Story (1995)          1995   \n",
       "1        70                      Lion King, The (1994)          1994   \n",
       "2        98     Snow White and the Seven Dwarfs (1937)          1937   \n",
       "3       131                   Wizard of Oz, The (1939)          1939   \n",
       "4       142                 Sound of Music, The (1965)          1965   \n",
       "5        49                           Star Wars (1977)          1977   \n",
       "6       171            Empire Strikes Back, The (1980)          1980   \n",
       "7       180                  Return of the Jedi (1983)          1997   \n",
       "8        81                       Jurassic Park (1993)          1993   \n",
       "9       251      Lost World: Jurassic Park, The (1997)          1997   \n",
       "10      173             Raiders of the Lost Ark (1981)          1981   \n",
       "11      209  Indiana Jones and the Last Crusade (1989)          1989   \n",
       "12       65             While You Were Sleeping (1995)          1995   \n",
       "13       87                Sleepless in Seattle (1993)          1993   \n",
       "14      254            My Best Friend's Wedding (1997)          1997   \n",
       "15       90     Nightmare Before Christmas, The (1993)          1993   \n",
       "16      199                        Shining, The (1980)          1980   \n",
       "17      218          Nightmare on Elm Street, A (1984)          1984   \n",
       "18      286                              Scream (1996)          1996   \n",
       "19      893                            Scream 2 (1997)          1997   \n",
       "\n",
       "    orig_item_id  c_parameter  \n",
       "0              1    -0.017818  \n",
       "1             71    -0.083676  \n",
       "2             99     0.807818  \n",
       "3            132     0.501377  \n",
       "4            143     0.565982  \n",
       "5             50     0.086464  \n",
       "6            172     0.832206  \n",
       "7            181     0.615166  \n",
       "8             82     0.704766  \n",
       "9            252     0.153030  \n",
       "10           174     0.561762  \n",
       "11           210     0.619021  \n",
       "12            66    -0.240191  \n",
       "13            88     0.801698  \n",
       "14           255     0.280272  \n",
       "15            91     0.252342  \n",
       "16           200     0.197453  \n",
       "17           219    -0.018336  \n",
       "18           288    -0.134032  \n",
       "19           895    -0.083332  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('select_movies/M2_select_movies_c_param.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 : Matrix Factorization using SGD and autograd\n",
    "As part of this we will be trying various models with five matrix factorization parameters. ($\\mu$, $b_i$, $c_i$, $u_i$ K dimensional vector for user i, $v_i$ - K dimensional vector for movie i)\n",
    "\n",
    "We'll try various values for factors length for each user and movie. We'll also try various regularization penalties on this model to find out best model.\n",
    "\n",
    "#### K = 2 and No Regularization:\n",
    "<img src='plots/M3_1.png' style='width:600px;height:600px;'>\n",
    "\n",
    "#### K = 10 and No Regularization:\n",
    "<img src='plots/M3_5.png' style='width:600px;height:600px;'>\n",
    "\n",
    "#### K = 50 and No Regularization:\n",
    "<img src='plots/M3_9.png' style='width:600px;height:600px;'>\n",
    "\n",
    "#### K = 2 and Regularization = 0.001:\n",
    "<img src='plots/M3_2.png' style='width:600px;height:600px;'>\n",
    "\n",
    "#### K = 10 and Regularization = 0.001:\n",
    "<img src='plots/M3_6.png' style='width:600px;height:600px;'>\n",
    "\n",
    "#### K = 50 and Regularization = 0.001:\n",
    "<img src='plots/M3_10.png' style='width:600px;height:600px;'>\n",
    "\n",
    "#### K = 2 and Regularization = 0.01:\n",
    "<img src='plots/M3_3.png' style='width:600px;height:600px;'>\n",
    "\n",
    "#### K = 10 and Regularization = 0.01:\n",
    "<img src='plots/M3_7.png' style='width:600px;height:600px;'>\n",
    "\n",
    "#### K = 50 and Regularization = 0.01:\n",
    "<img src='plots/M3_11.png' style='width:600px;height:600px;'>\n",
    "\n",
    "#### K = 2 and Regularization = 0.1:\n",
    "<img src='plots/M3_4.png' style='width:600px;height:600px;'>\n",
    "\n",
    "#### K = 10 and Regularization = 0.1:\n",
    "<img src='plots/M3_8.png' style='width:600px;height:600px;'>\n",
    "\n",
    "#### K = 50 and Regularization = 0.1:\n",
    "<img src='plots/M3_12.png' style='width:600px;height:600px;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best Performance:**\n",
    "\n",
    "* Train MAE : `0.723`\n",
    "* Valid MAE : `0.753`\n",
    "\n",
    "**Best Params:**\n",
    "\n",
    "* n_factors : `2` , alpha = `0.1`\n",
    "\n",
    "Please check file `M3_4.json` for checking parameter values for this best performing model for this part.\n",
    "\n",
    "After trying various parameters and penalty values we have found out that above mentioned parameter settings give best results.\n",
    "\n",
    "Our current model `M3` performs quite bettern than `M1` and little better than `M2`.We tried various vaues for n_factors like `2, 10, 50` and found out that value of 2 gives best results. Trying more than 50 parameter might not give good results as we have model which give good results for `n_factors = 2` and we tried bigger values than tha like 10,50 which did not give good results than it. Hence we don't recommend trying more than 50 for n_factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Movies Examination\n",
    "We have found out select movies embedding parameters `V` for movies with `K = 2` and `alpha = 0.1`. We'll plot it as scatter plot.\n",
    "\n",
    "We can see that Adventure/Scifi movies(Return of Jedi, Indiana Jones, Star Wars etc) has values which are quite around zero and right in graph.\n",
    "\n",
    "Cartoon/Horror/Animation movies(Lion King, Scream etc) has high positive/negative values for V2 and less value for V1. We can notice that all Adventure/Scifi are gathered around 0 in center and Horror/Cartoon/romantic movies are spread.\n",
    "\n",
    "<img src='select_movies/M3_4.png' style='width:600px;height:600px;'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>release_year</th>\n",
       "      <th>orig_item_id</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>[ 0.55649435 -0.03255801]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>Lion King, The (1994)</td>\n",
       "      <td>1994</td>\n",
       "      <td>71</td>\n",
       "      <td>[-0.23377262  0.44090488]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98</td>\n",
       "      <td>Snow White and the Seven Dwarfs (1937)</td>\n",
       "      <td>1937</td>\n",
       "      <td>99</td>\n",
       "      <td>[ 0.09000491 -0.08183166]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131</td>\n",
       "      <td>Wizard of Oz, The (1939)</td>\n",
       "      <td>1939</td>\n",
       "      <td>132</td>\n",
       "      <td>[ 0.19693762 -0.29926128]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142</td>\n",
       "      <td>Sound of Music, The (1965)</td>\n",
       "      <td>1965</td>\n",
       "      <td>143</td>\n",
       "      <td>[-0.25358477 -0.28140179]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>49</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "      <td>1977</td>\n",
       "      <td>50</td>\n",
       "      <td>[0.10592744 0.05422478]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>171</td>\n",
       "      <td>Empire Strikes Back, The (1980)</td>\n",
       "      <td>1980</td>\n",
       "      <td>172</td>\n",
       "      <td>[ 0.00340893 -0.01312453]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>180</td>\n",
       "      <td>Return of the Jedi (1983)</td>\n",
       "      <td>1997</td>\n",
       "      <td>181</td>\n",
       "      <td>[0.34272096 0.12824491]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>81</td>\n",
       "      <td>Jurassic Park (1993)</td>\n",
       "      <td>1993</td>\n",
       "      <td>82</td>\n",
       "      <td>[-0.43722235 -0.05117469]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>251</td>\n",
       "      <td>Lost World: Jurassic Park, The (1997)</td>\n",
       "      <td>1997</td>\n",
       "      <td>252</td>\n",
       "      <td>[ 0.50879849 -0.46065543]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>173</td>\n",
       "      <td>Raiders of the Lost Ark (1981)</td>\n",
       "      <td>1981</td>\n",
       "      <td>174</td>\n",
       "      <td>[0.23378598 0.01357567]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>209</td>\n",
       "      <td>Indiana Jones and the Last Crusade (1989)</td>\n",
       "      <td>1989</td>\n",
       "      <td>210</td>\n",
       "      <td>[0.60769021 0.11883519]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>65</td>\n",
       "      <td>While You Were Sleeping (1995)</td>\n",
       "      <td>1995</td>\n",
       "      <td>66</td>\n",
       "      <td>[-0.00133896  0.6299172 ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>87</td>\n",
       "      <td>Sleepless in Seattle (1993)</td>\n",
       "      <td>1993</td>\n",
       "      <td>88</td>\n",
       "      <td>[ 0.24953664 -0.22497756]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>254</td>\n",
       "      <td>My Best Friend's Wedding (1997)</td>\n",
       "      <td>1997</td>\n",
       "      <td>255</td>\n",
       "      <td>[-0.74329218 -0.17325982]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>90</td>\n",
       "      <td>Nightmare Before Christmas, The (1993)</td>\n",
       "      <td>1993</td>\n",
       "      <td>91</td>\n",
       "      <td>[-0.24843571  0.27487229]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>199</td>\n",
       "      <td>Shining, The (1980)</td>\n",
       "      <td>1980</td>\n",
       "      <td>200</td>\n",
       "      <td>[-0.1233313   0.27893922]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>218</td>\n",
       "      <td>Nightmare on Elm Street, A (1984)</td>\n",
       "      <td>1984</td>\n",
       "      <td>219</td>\n",
       "      <td>[-0.37194332 -0.59597771]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>286</td>\n",
       "      <td>Scream (1996)</td>\n",
       "      <td>1996</td>\n",
       "      <td>288</td>\n",
       "      <td>[0.02427319 0.42689353]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>893</td>\n",
       "      <td>Scream 2 (1997)</td>\n",
       "      <td>1997</td>\n",
       "      <td>895</td>\n",
       "      <td>[ 0.0161952  -0.55788967]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    item_id                                      title  release_year  \\\n",
       "0         0                           Toy Story (1995)          1995   \n",
       "1        70                      Lion King, The (1994)          1994   \n",
       "2        98     Snow White and the Seven Dwarfs (1937)          1937   \n",
       "3       131                   Wizard of Oz, The (1939)          1939   \n",
       "4       142                 Sound of Music, The (1965)          1965   \n",
       "5        49                           Star Wars (1977)          1977   \n",
       "6       171            Empire Strikes Back, The (1980)          1980   \n",
       "7       180                  Return of the Jedi (1983)          1997   \n",
       "8        81                       Jurassic Park (1993)          1993   \n",
       "9       251      Lost World: Jurassic Park, The (1997)          1997   \n",
       "10      173             Raiders of the Lost Ark (1981)          1981   \n",
       "11      209  Indiana Jones and the Last Crusade (1989)          1989   \n",
       "12       65             While You Were Sleeping (1995)          1995   \n",
       "13       87                Sleepless in Seattle (1993)          1993   \n",
       "14      254            My Best Friend's Wedding (1997)          1997   \n",
       "15       90     Nightmare Before Christmas, The (1993)          1993   \n",
       "16      199                        Shining, The (1980)          1980   \n",
       "17      218          Nightmare on Elm Street, A (1984)          1984   \n",
       "18      286                              Scream (1996)          1996   \n",
       "19      893                            Scream 2 (1997)          1997   \n",
       "\n",
       "    orig_item_id                          V  \n",
       "0              1  [ 0.55649435 -0.03255801]  \n",
       "1             71  [-0.23377262  0.44090488]  \n",
       "2             99  [ 0.09000491 -0.08183166]  \n",
       "3            132  [ 0.19693762 -0.29926128]  \n",
       "4            143  [-0.25358477 -0.28140179]  \n",
       "5             50    [0.10592744 0.05422478]  \n",
       "6            172  [ 0.00340893 -0.01312453]  \n",
       "7            181    [0.34272096 0.12824491]  \n",
       "8             82  [-0.43722235 -0.05117469]  \n",
       "9            252  [ 0.50879849 -0.46065543]  \n",
       "10           174    [0.23378598 0.01357567]  \n",
       "11           210    [0.60769021 0.11883519]  \n",
       "12            66  [-0.00133896  0.6299172 ]  \n",
       "13            88  [ 0.24953664 -0.22497756]  \n",
       "14           255  [-0.74329218 -0.17325982]  \n",
       "15            91  [-0.24843571  0.27487229]  \n",
       "16           200  [-0.1233313   0.27893922]  \n",
       "17           219  [-0.37194332 -0.59597771]  \n",
       "18           288    [0.02427319 0.42689353]  \n",
       "19           895  [ 0.0161952  -0.55788967]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('select_movies/M3_select_movies_V_4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 : Matrix Factorization with surprise\n",
    "We'll try surprise package provided by scikit which provides recommendation algorithms. We'll try SVD and other algorithms doing grid search on its parameters to find best results.\n",
    "\n",
    "We'll first load data according to format of surprise package below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(line_format='user item rating', sep=',')\n",
    "df = pd.read_csv('data_movie_lens_100k/ratings_train.csv')\n",
    "test_df = pd.read_csv('data_movie_lens_100k/ratings_test_masked.csv')\n",
    "data = Dataset.load_from_df(df, reader)\n",
    "trainset = data.build_full_trainset()\n",
    "test_data = Dataset.load_from_df(test_df, reader)\n",
    "#tesstset = test_data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try various values for parameters `n_factors`, regularization parameter `alpha` and `learning rate` to find best solution for our purpose using Grid Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MAE :  0.7346861177886957\n",
      "Best Params :  {'n_factors': 50, 'lr_all': 0.01, 'reg_all': 0.04}\n",
      "CPU times: user 4min 29s, sys: 2.24 s, total: 4min 31s\n",
      "Wall time: 4min 45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  4.7min finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#model_selection.cross_validate(SVD(), data, cv=3, verbose=True)\n",
    "\n",
    "param_grid = {'n_factors': [50,100], 'lr_all': [0.002, 0.005, 0.01],\n",
    "              'reg_all': [0.02, 0.04]}\n",
    "gs_svd = model_selection.GridSearchCV(SVD, param_grid, measures=['mae'], cv=5,\n",
    "                                 n_jobs=-1,joblib_verbose=-1)\n",
    "\n",
    "gs_svd.fit(data)\n",
    "\n",
    "print('Best MAE : ',gs_svd.best_score['mae'])\n",
    "print('Best Params : ',gs_svd.best_params['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_mae</th>\n",
       "      <th>split1_test_mae</th>\n",
       "      <th>split2_test_mae</th>\n",
       "      <th>split3_test_mae</th>\n",
       "      <th>split4_test_mae</th>\n",
       "      <th>mean_test_mae</th>\n",
       "      <th>std_test_mae</th>\n",
       "      <th>rank_test_mae</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_test_time</th>\n",
       "      <th>std_test_time</th>\n",
       "      <th>params</th>\n",
       "      <th>param_n_factors</th>\n",
       "      <th>param_lr_all</th>\n",
       "      <th>param_reg_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.755083</td>\n",
       "      <td>0.751907</td>\n",
       "      <td>0.756362</td>\n",
       "      <td>0.748218</td>\n",
       "      <td>0.759513</td>\n",
       "      <td>0.754217</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>9</td>\n",
       "      <td>6.690975</td>\n",
       "      <td>0.127371</td>\n",
       "      <td>0.703260</td>\n",
       "      <td>0.041234</td>\n",
       "      <td>{'n_factors': 50, 'lr_all': 0.002, 'reg_all': ...</td>\n",
       "      <td>50</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.755517</td>\n",
       "      <td>0.752670</td>\n",
       "      <td>0.756472</td>\n",
       "      <td>0.748916</td>\n",
       "      <td>0.759753</td>\n",
       "      <td>0.754666</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>10</td>\n",
       "      <td>6.710903</td>\n",
       "      <td>0.114255</td>\n",
       "      <td>0.680635</td>\n",
       "      <td>0.007109</td>\n",
       "      <td>{'n_factors': 50, 'lr_all': 0.002, 'reg_all': ...</td>\n",
       "      <td>50</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.745832</td>\n",
       "      <td>0.741731</td>\n",
       "      <td>0.742494</td>\n",
       "      <td>0.734492</td>\n",
       "      <td>0.745278</td>\n",
       "      <td>0.741965</td>\n",
       "      <td>0.004052</td>\n",
       "      <td>5</td>\n",
       "      <td>6.601332</td>\n",
       "      <td>0.061055</td>\n",
       "      <td>0.699836</td>\n",
       "      <td>0.032193</td>\n",
       "      <td>{'n_factors': 50, 'lr_all': 0.005, 'reg_all': ...</td>\n",
       "      <td>50</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.744463</td>\n",
       "      <td>0.738777</td>\n",
       "      <td>0.741888</td>\n",
       "      <td>0.735225</td>\n",
       "      <td>0.746422</td>\n",
       "      <td>0.741355</td>\n",
       "      <td>0.003996</td>\n",
       "      <td>4</td>\n",
       "      <td>6.741702</td>\n",
       "      <td>0.140377</td>\n",
       "      <td>0.705332</td>\n",
       "      <td>0.039922</td>\n",
       "      <td>{'n_factors': 50, 'lr_all': 0.005, 'reg_all': ...</td>\n",
       "      <td>50</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.756672</td>\n",
       "      <td>0.749437</td>\n",
       "      <td>0.751443</td>\n",
       "      <td>0.741449</td>\n",
       "      <td>0.758484</td>\n",
       "      <td>0.751497</td>\n",
       "      <td>0.006013</td>\n",
       "      <td>7</td>\n",
       "      <td>6.591766</td>\n",
       "      <td>0.058610</td>\n",
       "      <td>0.678783</td>\n",
       "      <td>0.005240</td>\n",
       "      <td>{'n_factors': 50, 'lr_all': 0.01, 'reg_all': 0...</td>\n",
       "      <td>50</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.738649</td>\n",
       "      <td>0.734206</td>\n",
       "      <td>0.737502</td>\n",
       "      <td>0.725821</td>\n",
       "      <td>0.737252</td>\n",
       "      <td>0.734686</td>\n",
       "      <td>0.004670</td>\n",
       "      <td>1</td>\n",
       "      <td>6.534723</td>\n",
       "      <td>0.057413</td>\n",
       "      <td>0.678955</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>{'n_factors': 50, 'lr_all': 0.01, 'reg_all': 0...</td>\n",
       "      <td>50</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.757543</td>\n",
       "      <td>0.755874</td>\n",
       "      <td>0.756901</td>\n",
       "      <td>0.750068</td>\n",
       "      <td>0.760197</td>\n",
       "      <td>0.756117</td>\n",
       "      <td>0.003345</td>\n",
       "      <td>12</td>\n",
       "      <td>10.866247</td>\n",
       "      <td>0.066848</td>\n",
       "      <td>0.686974</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>{'n_factors': 100, 'lr_all': 0.002, 'reg_all':...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.757324</td>\n",
       "      <td>0.754063</td>\n",
       "      <td>0.757445</td>\n",
       "      <td>0.748601</td>\n",
       "      <td>0.761073</td>\n",
       "      <td>0.755701</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>11</td>\n",
       "      <td>10.857728</td>\n",
       "      <td>0.063923</td>\n",
       "      <td>0.684522</td>\n",
       "      <td>0.003517</td>\n",
       "      <td>{'n_factors': 100, 'lr_all': 0.002, 'reg_all':...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.746535</td>\n",
       "      <td>0.740149</td>\n",
       "      <td>0.746333</td>\n",
       "      <td>0.736632</td>\n",
       "      <td>0.747809</td>\n",
       "      <td>0.743492</td>\n",
       "      <td>0.004341</td>\n",
       "      <td>6</td>\n",
       "      <td>10.834855</td>\n",
       "      <td>0.065292</td>\n",
       "      <td>0.682732</td>\n",
       "      <td>0.005548</td>\n",
       "      <td>{'n_factors': 100, 'lr_all': 0.005, 'reg_all':...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.743808</td>\n",
       "      <td>0.740284</td>\n",
       "      <td>0.740180</td>\n",
       "      <td>0.732144</td>\n",
       "      <td>0.746517</td>\n",
       "      <td>0.740586</td>\n",
       "      <td>0.004839</td>\n",
       "      <td>3</td>\n",
       "      <td>10.889194</td>\n",
       "      <td>0.086407</td>\n",
       "      <td>0.684015</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>{'n_factors': 100, 'lr_all': 0.005, 'reg_all':...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.755304</td>\n",
       "      <td>0.752035</td>\n",
       "      <td>0.753278</td>\n",
       "      <td>0.746857</td>\n",
       "      <td>0.756656</td>\n",
       "      <td>0.752826</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>8</td>\n",
       "      <td>10.849467</td>\n",
       "      <td>0.040282</td>\n",
       "      <td>0.686305</td>\n",
       "      <td>0.006669</td>\n",
       "      <td>{'n_factors': 100, 'lr_all': 0.01, 'reg_all': ...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.736728</td>\n",
       "      <td>0.733950</td>\n",
       "      <td>0.737314</td>\n",
       "      <td>0.728260</td>\n",
       "      <td>0.740317</td>\n",
       "      <td>0.735314</td>\n",
       "      <td>0.004066</td>\n",
       "      <td>2</td>\n",
       "      <td>10.775159</td>\n",
       "      <td>0.076271</td>\n",
       "      <td>0.675185</td>\n",
       "      <td>0.004252</td>\n",
       "      <td>{'n_factors': 100, 'lr_all': 0.01, 'reg_all': ...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    split0_test_mae  split1_test_mae  split2_test_mae  split3_test_mae  \\\n",
       "0          0.755083         0.751907         0.756362         0.748218   \n",
       "1          0.755517         0.752670         0.756472         0.748916   \n",
       "2          0.745832         0.741731         0.742494         0.734492   \n",
       "3          0.744463         0.738777         0.741888         0.735225   \n",
       "4          0.756672         0.749437         0.751443         0.741449   \n",
       "5          0.738649         0.734206         0.737502         0.725821   \n",
       "6          0.757543         0.755874         0.756901         0.750068   \n",
       "7          0.757324         0.754063         0.757445         0.748601   \n",
       "8          0.746535         0.740149         0.746333         0.736632   \n",
       "9          0.743808         0.740284         0.740180         0.732144   \n",
       "10         0.755304         0.752035         0.753278         0.746857   \n",
       "11         0.736728         0.733950         0.737314         0.728260   \n",
       "\n",
       "    split4_test_mae  mean_test_mae  std_test_mae  rank_test_mae  \\\n",
       "0          0.759513       0.754217      0.003866              9   \n",
       "1          0.759753       0.754666      0.003658             10   \n",
       "2          0.745278       0.741965      0.004052              5   \n",
       "3          0.746422       0.741355      0.003996              4   \n",
       "4          0.758484       0.751497      0.006013              7   \n",
       "5          0.737252       0.734686      0.004670              1   \n",
       "6          0.760197       0.756117      0.003345             12   \n",
       "7          0.761073       0.755701      0.004186             11   \n",
       "8          0.747809       0.743492      0.004341              6   \n",
       "9          0.746517       0.740586      0.004839              3   \n",
       "10         0.756656       0.752826      0.003384              8   \n",
       "11         0.740317       0.735314      0.004066              2   \n",
       "\n",
       "    mean_fit_time  std_fit_time  mean_test_time  std_test_time  \\\n",
       "0        6.690975      0.127371        0.703260       0.041234   \n",
       "1        6.710903      0.114255        0.680635       0.007109   \n",
       "2        6.601332      0.061055        0.699836       0.032193   \n",
       "3        6.741702      0.140377        0.705332       0.039922   \n",
       "4        6.591766      0.058610        0.678783       0.005240   \n",
       "5        6.534723      0.057413        0.678955       0.001780   \n",
       "6       10.866247      0.066848        0.686974       0.002104   \n",
       "7       10.857728      0.063923        0.684522       0.003517   \n",
       "8       10.834855      0.065292        0.682732       0.005548   \n",
       "9       10.889194      0.086407        0.684015       0.004069   \n",
       "10      10.849467      0.040282        0.686305       0.006669   \n",
       "11      10.775159      0.076271        0.675185       0.004252   \n",
       "\n",
       "                                               params  param_n_factors  \\\n",
       "0   {'n_factors': 50, 'lr_all': 0.002, 'reg_all': ...               50   \n",
       "1   {'n_factors': 50, 'lr_all': 0.002, 'reg_all': ...               50   \n",
       "2   {'n_factors': 50, 'lr_all': 0.005, 'reg_all': ...               50   \n",
       "3   {'n_factors': 50, 'lr_all': 0.005, 'reg_all': ...               50   \n",
       "4   {'n_factors': 50, 'lr_all': 0.01, 'reg_all': 0...               50   \n",
       "5   {'n_factors': 50, 'lr_all': 0.01, 'reg_all': 0...               50   \n",
       "6   {'n_factors': 100, 'lr_all': 0.002, 'reg_all':...              100   \n",
       "7   {'n_factors': 100, 'lr_all': 0.002, 'reg_all':...              100   \n",
       "8   {'n_factors': 100, 'lr_all': 0.005, 'reg_all':...              100   \n",
       "9   {'n_factors': 100, 'lr_all': 0.005, 'reg_all':...              100   \n",
       "10  {'n_factors': 100, 'lr_all': 0.01, 'reg_all': ...              100   \n",
       "11  {'n_factors': 100, 'lr_all': 0.01, 'reg_all': ...              100   \n",
       "\n",
       "    param_lr_all  param_reg_all  \n",
       "0          0.002           0.02  \n",
       "1          0.002           0.04  \n",
       "2          0.005           0.02  \n",
       "3          0.005           0.04  \n",
       "4          0.010           0.02  \n",
       "5          0.010           0.04  \n",
       "6          0.002           0.02  \n",
       "7          0.002           0.04  \n",
       "8          0.005           0.02  \n",
       "9          0.005           0.04  \n",
       "10         0.010           0.02  \n",
       "11         0.010           0.04  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_results = pd.DataFrame.from_dict(gs_svd.cv_results)\n",
    "gridsearch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9344\n",
      "MAE:  0.7359\n"
     ]
    }
   ],
   "source": [
    "#data = Dataset.load_from_df(df, reader)\n",
    "trainset, testset = model_selection.train_test_split(data, test_size=.20,random_state=123)\n",
    "svd = SVD(n_factors=50, reg_all =0.04, lr_all=0.01)\n",
    "svd.fit(trainset)\n",
    "\n",
    "predictions = svd.test(testset)\n",
    "\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)\n",
    "\n",
    "preds = np.zeros(len(test_df),dtype=np.float64)\n",
    "for i, (uid,iid) in  enumerate(zip(test_df.user_id,test_df.item_id)):\n",
    "    preds[i] = svd.predict(uid,iid).est\n",
    "\n",
    "np.savetxt(os.path.join('test_preds', \"M4_SVD.txt\"), preds,newline='\\r\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best Performance:**\n",
    "\n",
    "* Train MAE : `0.734`\n",
    "* Valid MAE : `0.735`\n",
    "\n",
    "**Best Params:**\n",
    "\n",
    "* n_factors : `50` , alpha = `0.04`, learning_rate = `0.01`\n",
    "\n",
    "We have found out using SVD that above mentioned parameters best performs using SVD. It's noticeable that `M4` performs bit better than `M3` and `M2` & quite better than `M1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5\n",
    "We'll try various model provided with `surprise` package to see whether there is any performance improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BaseOnly Model with various parameters\n",
    "We are trying 2 optimization methods ALS(Alternating Least Squares) and SGD with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ALS\n",
      "RMSE: 0.9446\n",
      "MAE:  0.7482\n"
     ]
    }
   ],
   "source": [
    "print('Using ALS')\n",
    "bsl_options = {'method': 'als',\n",
    "               'n_epochs': 15,\n",
    "               'reg_u': 12,\n",
    "               'reg_i': 5\n",
    "               }\n",
    "baseline = BaselineOnly(bsl_options=bsl_options,verbose=False)\n",
    "trainset, testset = model_selection.train_test_split(data, test_size=.20,random_state=123)\n",
    "baseline.fit(trainset)\n",
    "predictions = baseline.test(testset)\n",
    "\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)\n",
    "\n",
    "preds = np.zeros(len(test_df),dtype=np.float64)\n",
    "for i, (uid,iid) in  enumerate(zip(test_df.user_id,test_df.item_id)):\n",
    "    preds[i] = baseline.predict(uid,iid).est\n",
    "\n",
    "np.savetxt(os.path.join('test_preds', \"M5_BASELINE_ONLY.txt\"), preds,newline='\\r\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SGD\n",
      "RMSE: 0.9460\n",
      "MAE:  0.7477\n"
     ]
    }
   ],
   "source": [
    "print('Using SGD')\n",
    "bsl_options = {'method': 'sgd',\n",
    "               'n_epochs': 10,\n",
    "               'learning_rate': .01,\n",
    "               }\n",
    "baseline = BaselineOnly(bsl_options=bsl_options,verbose=False)\n",
    "trainset, testset = model_selection.train_test_split(data, test_size=.20,random_state=123)\n",
    "baseline.fit(trainset)\n",
    "predictions = baseline.test(testset)\n",
    "\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)\n",
    "\n",
    "preds = np.zeros(len(test_df),dtype=np.float64)\n",
    "for i, (uid,iid) in  enumerate(zip(test_df.user_id,test_df.item_id)):\n",
    "    preds[i] = baseline.predict(uid,iid).est\n",
    "\n",
    "np.savetxt(os.path.join('test_preds', \"M5_BASELINE_ONLY_2.txt\"), preds,newline='\\r\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNNBasic with various parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0320\n",
      "MAE:  0.8179\n"
     ]
    }
   ],
   "source": [
    "sim_options = {'name': 'cosine',\n",
    "               'user_based': False  # compute  similarities between items\n",
    "               }\n",
    "knnbasic = KNNBasic(sim_options=sim_options,verbose=False)\n",
    "trainset, testset = model_selection.train_test_split(data, test_size=.20, random_state=123)\n",
    "knnbasic.fit(trainset)\n",
    "predictions = knnbasic.test(testset)\n",
    "\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)\n",
    "\n",
    "preds = np.zeros(len(test_df),dtype=np.float64)\n",
    "for i, (uid,iid) in  enumerate(zip(test_df.user_id,test_df.item_id)):\n",
    "    preds[i] = knnbasic.predict(uid,iid).est\n",
    "\n",
    "np.savetxt(os.path.join('test_preds', \"M5_KNN_BASIC.txt\"), preds,newline='\\r\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0108\n",
      "MAE:  0.7992\n"
     ]
    }
   ],
   "source": [
    "sim_options = {'name': 'pearson_baseline',\n",
    "               'shrinkage': 0  # no shrinkage\n",
    "               }\n",
    "knnbasic = KNNBasic(sim_options=sim_options, verbose=False)\n",
    "trainset, testset = model_selection.train_test_split(data, test_size=.20, random_state=123)\n",
    "\n",
    "knnbasic.fit(trainset)\n",
    "\n",
    "predictions = knnbasic.test(testset)\n",
    "\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)\n",
    "\n",
    "preds = np.zeros(len(test_df),dtype=np.float64)\n",
    "for i, (uid,iid) in  enumerate(zip(test_df.user_id,test_df.item_id)):\n",
    "    preds[i] = knnbasic.predict(uid,iid).est\n",
    "\n",
    "np.savetxt(os.path.join('test_preds', \"M5_KNN_BASIC_2.txt\"), preds,newline='\\r\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that even after trying various models with various paramters results seem to be not improving much. It seem that we have reached limitation and MAE is not improving further than `0.73`.\n",
    "\n",
    "We tried all above models with Evaluation and training with MAE. It won't make much difference if we use RMSE for training and MAE for evaluation which we can see from above experiments. M4 and M5 are training and evaluation with MAE. M1,M2 and M3 are training with RMSE and evaluation with MAE. We can notice that after certain point MAE is not improving further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "CPU times: user 22min 35s, sys: 2.09 s, total: 22min 37s\n",
      "Wall time: 22min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "benchmark = []\n",
    "\n",
    "for algorithm in [SVD(), SVDpp(), SlopeOne(), NMF(), NormalPredictor(), KNNBaseline(), KNNBasic(), KNNWithMeans(), KNNWithZScore(), BaselineOnly(), CoClustering()]:\n",
    "    # Perform cross validation\n",
    "    results = model_selection.cross_validate(algorithm, data, measures=['mae'], cv=3, verbose=False)\n",
    "    \n",
    "    # Get results & append algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    benchmark.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_mae</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVDpp</th>\n",
       "      <td>0.732839</td>\n",
       "      <td>325.171916</td>\n",
       "      <td>24.069372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBaseline</th>\n",
       "      <td>0.740864</td>\n",
       "      <td>1.343137</td>\n",
       "      <td>16.202552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlopeOne</th>\n",
       "      <td>0.748737</td>\n",
       "      <td>1.365101</td>\n",
       "      <td>10.057557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>0.750158</td>\n",
       "      <td>9.587787</td>\n",
       "      <td>1.223440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaselineOnly</th>\n",
       "      <td>0.753201</td>\n",
       "      <td>0.411849</td>\n",
       "      <td>0.980326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithZScore</th>\n",
       "      <td>0.754066</td>\n",
       "      <td>0.967186</td>\n",
       "      <td>13.914732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithMeans</th>\n",
       "      <td>0.756573</td>\n",
       "      <td>0.816010</td>\n",
       "      <td>12.757979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoClustering</th>\n",
       "      <td>0.766100</td>\n",
       "      <td>3.525722</td>\n",
       "      <td>1.220468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF</th>\n",
       "      <td>0.770809</td>\n",
       "      <td>9.866300</td>\n",
       "      <td>1.164640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBasic</th>\n",
       "      <td>0.785346</td>\n",
       "      <td>0.730703</td>\n",
       "      <td>11.466362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NormalPredictor</th>\n",
       "      <td>1.221591</td>\n",
       "      <td>0.359358</td>\n",
       "      <td>1.424548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 test_mae    fit_time  test_time\n",
       "Algorithm                                       \n",
       "SVDpp            0.732839  325.171916  24.069372\n",
       "KNNBaseline      0.740864    1.343137  16.202552\n",
       "SlopeOne         0.748737    1.365101  10.057557\n",
       "SVD              0.750158    9.587787   1.223440\n",
       "BaselineOnly     0.753201    0.411849   0.980326\n",
       "KNNWithZScore    0.754066    0.967186  13.914732\n",
       "KNNWithMeans     0.756573    0.816010  12.757979\n",
       "CoClustering     0.766100    3.525722   1.220468\n",
       "NMF              0.770809    9.866300   1.164640\n",
       "KNNBasic         0.785346    0.730703  11.466362\n",
       "NormalPredictor  1.221591    0.359358   1.424548"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_mae')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above after trying various models that `SVDpp` performs better than all of them. We'll try it for guessing ratings of test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  5.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MAE :  0.7329844869388864\n",
      "Best Params :  {'n_factors': 20, 'lr_all': 0.01, 'reg_all': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  7.2min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_factors': [20, 50, 100], 'lr_all': [0.002, 0.007, 0.01],\n",
    "              'reg_all': [0.02, 0.04]}\n",
    "\n",
    "gs_svdpp = model_selection.GridSearchCV(SVD, param_grid, measures=['mae'], cv=5,\n",
    "                                 n_jobs=-1,joblib_verbose=-1)\n",
    "\n",
    "gs_svdpp.fit(data)\n",
    "\n",
    "print('Best MAE : ',gs_svdpp.best_score['mae'])\n",
    "print('Best Params : ',gs_svdpp.best_params['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9252\n",
      "MAE:  0.7266\n",
      "CPU times: user 8min 9s, sys: 267 ms, total: 8min 10s\n",
      "Wall time: 8min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svdpp = SVDpp(n_factors = 20, lr_all = 0.01, reg_all = 0.04)\n",
    "trainset, testset = model_selection.train_test_split(data, test_size=.20, random_state=123)\n",
    "\n",
    "svdpp.fit(trainset)\n",
    "\n",
    "predictions = svdpp.test(testset)\n",
    "\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)\n",
    "\n",
    "preds = np.zeros(len(test_df),dtype=np.float64)\n",
    "for i, (uid,iid) in  enumerate(zip(test_df.user_id,test_df.item_id)):\n",
    "    preds[i] = svdpp.predict(uid,iid).est\n",
    "\n",
    "np.savetxt(os.path.join('test_preds', \"M5_SVDPP.txt\"), preds,newline='\\r\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please make a note that SVDpp model has give best result till now with MAE of `0.731`. \n",
    "\n",
    "**Best Performance:**\n",
    "* Train MAE: `0.731`\n",
    "* Test MAE : `0.727`\n",
    "\n",
    "**Best Params:**\n",
    "* n_factors: `20`, alpha: `0.04` , learning rate: `0.02`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6 : Predicting Gender from User Embedding Vectors (U) learned by best M3 model.\n",
    "We'll load User Embedding Vector from our best M3 model and then try to predict user's gender based on this paramters.\n",
    "\n",
    "We have mentioned above that model `M3_4.json` has paramters details for embeddings of best performing model. We also have mentioned that it performed best with `n_factors = 2` and `alpha = 0.1`. We'll load `M3_4.json` into memory and retrieve User Embedding Vector from it which we'll further use to guess user gender.\n",
    "\n",
    "We'll try various scikit-learn models to find out which one performs best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_data = pd.read_csv('data_movie_lens_100k/user_info.csv')\n",
    "\n",
    "params = json.load(open('model_params/M3_4.json'))\n",
    "U = np.array(params['U'])\n",
    "U.shape, users_data.is_male.values.shape\n",
    "X, Y = U, users_data.is_male.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score :  0.7104984093319194\n",
      "Best Params :  {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "params_lr = {\n",
    "    'logisticregression__C' : [0.1,1.0,10],\n",
    "    'logisticregression__penalty' : ['l1','l2']\n",
    "}\n",
    "pipeline_lr = make_pipeline(LogisticRegression())\n",
    "\n",
    "grid_lr = GridSearchCV(pipeline_lr, param_grid=params_lr, cv = 5, n_jobs=-1)\n",
    "grid_lr.fit(X, Y)\n",
    "\n",
    "print('Best Score : ',grid_lr.best_score_)\n",
    "print('Best Params : ', grid_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score :  0.711558854718982\n",
      "Best Params :  {'svc__C': 1.0, 'svc__gamma': 10}\n"
     ]
    }
   ],
   "source": [
    "params_svc = {\n",
    "    'svc__C' : [0.1,1.0,10],\n",
    "    'svc__gamma' : [0.01,0.1,1.0,10,100, 'auto','scale']\n",
    "}\n",
    "pipeline_svc = make_pipeline(SVC())\n",
    "\n",
    "grid_svc = GridSearchCV(pipeline_svc, param_grid=params_svc, cv = 5, n_jobs=-1)\n",
    "grid_svc.fit(X, Y)\n",
    "\n",
    "print('Best Score : ',grid_svc.best_score_)\n",
    "print('Best Params : ', grid_svc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score :  0.7104984093319194\n",
      "Best Params :  {'randomforestclassifier__max_depth': 3, 'randomforestclassifier__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "params_rf = {\n",
    "    'randomforestclassifier__max_depth' : [None,3,4,5],\n",
    "    'randomforestclassifier__n_estimators' : [100,200,500]\n",
    "}\n",
    "pipeline_rf = make_pipeline(RandomForestClassifier())\n",
    "\n",
    "grid_rf = GridSearchCV(pipeline_rf, param_grid=params_rf, cv = 5, n_jobs=-1)\n",
    "grid_rf.fit(X, Y)\n",
    "\n",
    "print('Best Score : ',grid_rf.best_score_)\n",
    "print('Best Params : ', grid_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.999262190783734\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(log_loss(Y, grid_lr.predict(X)))\n",
    "conf_mat = confusion_matrix(Y, grid_lr.predict(X))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.669612792776533\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(log_loss(Y, grid_svc.predict(X)))\n",
    "conf_mat = confusion_matrix(Y, grid_svc.predict(X))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.559734182397635\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(log_loss(Y, grid_rf.predict(X)))\n",
    "conf_mat = confusion_matrix(Y, grid_rf.predict(X))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that even after trying various good paramters we are not able to get good model whic fits data properly and properly predicts gender. It seems that our best `M3` model does not have enough information to predict gender properly.\n",
    "\n",
    "It's little bit better than chance but not that good enough. I feel that its almost like chance only and shouldn't be used for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
