{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise\n",
    "from surprise import BaselineOnly, Dataset, KNNBasic, KNNBaseline, NormalPredictor, SVD, SlopeOne, NMF, SVDpp, KNNWithMeans, KNNWithZScore, CoClustering\n",
    "from surprise import accuracy, evaluate, Reader, model_selection\n",
    "import utils\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, log_loss\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mAbstractBaseCollabFilterSGD.py\u001b[0m*    \u001b[01;34mmodel_params\u001b[0m/\r\n",
      "\u001b[01;32mCollabFilterMeanOnly.py\u001b[0m*           \u001b[01;34mplots\u001b[0m/\r\n",
      "\u001b[01;32mCollabFilterMeanOnly.py~\u001b[0m*          Project systems updated.pdf\r\n",
      "\u001b[01;32mCollabFilterOneScalarPerItem.py\u001b[0m*   \u001b[01;34m__pycache__\u001b[0m/\r\n",
      "\u001b[01;32mCollabFilterOneScalarPerItem.py~\u001b[0m*  \u001b[01;32mrequirements.txt\u001b[0m*\r\n",
      "\u001b[01;32mCollabFilterOneVectorPerItem.py\u001b[0m*   \u001b[01;34mselect_movies\u001b[0m/\r\n",
      "\u001b[01;32mCollabFilterOneVectorPerItem.py~\u001b[0m*  surprise-recommendation.ipynb\r\n",
      "\u001b[01;34mdata_movie_lens_100k\u001b[0m/              \u001b[01;34mtest_preds\u001b[0m/\r\n",
      "\u001b[01;32mIntroduction_Autograd.ipynb\u001b[0m*       \u001b[01;32mutils.py\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Simple Baseline Model with SGD and autograd\n",
    "As a part of this model, we are guessing constant rating for each of user and movie id combinations. We'll be predicting same value for each combinations. We'll try to find out optimal value of this prediction $\\mu$ so that Mean Absolute Error is less as much as possible.\n",
    "\n",
    "#### Epochs vs MAE for train & validation sets\n",
    "<img src='plots/M1.png' style='width:600px;height:600px;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regularization:** Adding regularization is not helping much to improve performance. We tried adding L2 regularization based on parameter $\\mu$.\n",
    "\n",
    "**Performance Without adding reguarization:**\n",
    "\n",
    "* Train MAE : `0.941`\n",
    "* Validation MAE : `0.943`\n",
    "\n",
    "**Performance adding L2 reguarization:**\n",
    "\n",
    "* Train MAE : `0.941`\n",
    "* Validation MAE : `0.943`\n",
    "\n",
    "**Best Score $\\mu$ :** `3.54`\n",
    "\n",
    "**Clsoed Form Solution :** One can also take `mean` of trainset ratings and guess it as rating for each test set combinations. It won't require to use SGD at all. Average rating on train set is `3.53` which matches with results of SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 : One Scaler Per Item Baseline with SGD and autograd\n",
    "We are using one scaler per user and one scaler per movie for this model. We then optimize this scalers for each movie and user through training and evaluating as MAE.\n",
    "\n",
    "#### Epochs vs MAE for train and validation set\n",
    "<img src='plots/M2.png' style='width:600px;height:600px;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`M2` model is quite an improvement in terms of performance from `M1` model as it guesses different ratings for each `(user_id, movie_id)` combinations whereas `M1` guesses same rating for each combinations.\n",
    "\n",
    "* Train MAE : `0.727`\n",
    "* Validation MAE : `0.744`\n",
    "\n",
    "**Best Params** : Please refer to file `M2.json` under folder `model_params` for getting idea about model's trained parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Movies Examination\n",
    "We have saved `c_per_item` parameter for selected set of movies saved in `select_movies.csv` file.\n",
    "\n",
    "We have noticed that `Animation/Cartoon/Horror` movies (Toy Story, Lion King, Scream etc) has very `negative` values for parameter `c` whereas `scifi/adventure` movies (Empire Strikes Back, Snow White and Seven Dwarves) has quite `high` values for paramer `c`. Romantic comedy movie like Sleepless in Seattle (1993)\talso has quite high value for parameter `c`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>release_year</th>\n",
       "      <th>orig_item_id</th>\n",
       "      <th>c_parameter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.017818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>Lion King, The (1994)</td>\n",
       "      <td>1994</td>\n",
       "      <td>71</td>\n",
       "      <td>-0.083676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98</td>\n",
       "      <td>Snow White and the Seven Dwarfs (1937)</td>\n",
       "      <td>1937</td>\n",
       "      <td>99</td>\n",
       "      <td>0.807818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131</td>\n",
       "      <td>Wizard of Oz, The (1939)</td>\n",
       "      <td>1939</td>\n",
       "      <td>132</td>\n",
       "      <td>0.501377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142</td>\n",
       "      <td>Sound of Music, The (1965)</td>\n",
       "      <td>1965</td>\n",
       "      <td>143</td>\n",
       "      <td>0.565982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>49</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "      <td>1977</td>\n",
       "      <td>50</td>\n",
       "      <td>0.086464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>171</td>\n",
       "      <td>Empire Strikes Back, The (1980)</td>\n",
       "      <td>1980</td>\n",
       "      <td>172</td>\n",
       "      <td>0.832206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>180</td>\n",
       "      <td>Return of the Jedi (1983)</td>\n",
       "      <td>1997</td>\n",
       "      <td>181</td>\n",
       "      <td>0.615166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>81</td>\n",
       "      <td>Jurassic Park (1993)</td>\n",
       "      <td>1993</td>\n",
       "      <td>82</td>\n",
       "      <td>0.704766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>251</td>\n",
       "      <td>Lost World: Jurassic Park, The (1997)</td>\n",
       "      <td>1997</td>\n",
       "      <td>252</td>\n",
       "      <td>0.153030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>173</td>\n",
       "      <td>Raiders of the Lost Ark (1981)</td>\n",
       "      <td>1981</td>\n",
       "      <td>174</td>\n",
       "      <td>0.561762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>209</td>\n",
       "      <td>Indiana Jones and the Last Crusade (1989)</td>\n",
       "      <td>1989</td>\n",
       "      <td>210</td>\n",
       "      <td>0.619021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>65</td>\n",
       "      <td>While You Were Sleeping (1995)</td>\n",
       "      <td>1995</td>\n",
       "      <td>66</td>\n",
       "      <td>-0.240191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>87</td>\n",
       "      <td>Sleepless in Seattle (1993)</td>\n",
       "      <td>1993</td>\n",
       "      <td>88</td>\n",
       "      <td>0.801698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>254</td>\n",
       "      <td>My Best Friend's Wedding (1997)</td>\n",
       "      <td>1997</td>\n",
       "      <td>255</td>\n",
       "      <td>0.280272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>90</td>\n",
       "      <td>Nightmare Before Christmas, The (1993)</td>\n",
       "      <td>1993</td>\n",
       "      <td>91</td>\n",
       "      <td>0.252342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>199</td>\n",
       "      <td>Shining, The (1980)</td>\n",
       "      <td>1980</td>\n",
       "      <td>200</td>\n",
       "      <td>0.197453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>218</td>\n",
       "      <td>Nightmare on Elm Street, A (1984)</td>\n",
       "      <td>1984</td>\n",
       "      <td>219</td>\n",
       "      <td>-0.018336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>286</td>\n",
       "      <td>Scream (1996)</td>\n",
       "      <td>1996</td>\n",
       "      <td>288</td>\n",
       "      <td>-0.134032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>893</td>\n",
       "      <td>Scream 2 (1997)</td>\n",
       "      <td>1997</td>\n",
       "      <td>895</td>\n",
       "      <td>-0.083332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    item_id                                      title  release_year  \\\n",
       "0         0                           Toy Story (1995)          1995   \n",
       "1        70                      Lion King, The (1994)          1994   \n",
       "2        98     Snow White and the Seven Dwarfs (1937)          1937   \n",
       "3       131                   Wizard of Oz, The (1939)          1939   \n",
       "4       142                 Sound of Music, The (1965)          1965   \n",
       "5        49                           Star Wars (1977)          1977   \n",
       "6       171            Empire Strikes Back, The (1980)          1980   \n",
       "7       180                  Return of the Jedi (1983)          1997   \n",
       "8        81                       Jurassic Park (1993)          1993   \n",
       "9       251      Lost World: Jurassic Park, The (1997)          1997   \n",
       "10      173             Raiders of the Lost Ark (1981)          1981   \n",
       "11      209  Indiana Jones and the Last Crusade (1989)          1989   \n",
       "12       65             While You Were Sleeping (1995)          1995   \n",
       "13       87                Sleepless in Seattle (1993)          1993   \n",
       "14      254            My Best Friend's Wedding (1997)          1997   \n",
       "15       90     Nightmare Before Christmas, The (1993)          1993   \n",
       "16      199                        Shining, The (1980)          1980   \n",
       "17      218          Nightmare on Elm Street, A (1984)          1984   \n",
       "18      286                              Scream (1996)          1996   \n",
       "19      893                            Scream 2 (1997)          1997   \n",
       "\n",
       "    orig_item_id  c_parameter  \n",
       "0              1    -0.017818  \n",
       "1             71    -0.083676  \n",
       "2             99     0.807818  \n",
       "3            132     0.501377  \n",
       "4            143     0.565982  \n",
       "5             50     0.086464  \n",
       "6            172     0.832206  \n",
       "7            181     0.615166  \n",
       "8             82     0.704766  \n",
       "9            252     0.153030  \n",
       "10           174     0.561762  \n",
       "11           210     0.619021  \n",
       "12            66    -0.240191  \n",
       "13            88     0.801698  \n",
       "14           255     0.280272  \n",
       "15            91     0.252342  \n",
       "16           200     0.197453  \n",
       "17           219    -0.018336  \n",
       "18           288    -0.134032  \n",
       "19           895    -0.083332  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('select_movies/M2_select_movies_c_param.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 : Matrix Factorization using SGD and autograd\n",
    "As part of this we will be trying various models with five matrix factorization parameters. ($\\mu$, $b_i$, $c_i$, $u_i$ K dimensional vector for user i, $v_i$ - K dimensional vector for movie i)\n",
    "\n",
    "We'll try various values for factors length for each user and movie. We'll also try various regularization penalties on this model to find out best model.\n",
    "\n",
    "#### K = 2 and No Regularization:\n",
    "<img src='plots/M3_1.png' style='width:600px;height:600px;'>\n",
    "#### K = 10 and No Regularization:\n",
    "<img src='plots/M3_5.png' style='width:600px;height:600px;'>\n",
    "#### K = 50 and No Regularization:\n",
    "<img src='plots/M3_9.png' style='width:600px;height:600px;'>\n",
    "\n",
    "#### K = 2 and Regularization = 0.001:\n",
    "<img src='plots/M3_2.png' style='width:600px;height:600px;'>\n",
    "#### K = 10 and Regularization = 0.001:\n",
    "<img src='plots/M3_6.png' style='width:600px;height:600px;'>\n",
    "#### K = 50 and Regularization = 0.001:\n",
    "<img src='plots/M3_10.png' style='width:600px;height:600px;'>\n",
    "\n",
    "#### K = 2 and Regularization = 0.01:\n",
    "<img src='plots/M3_3.png' style='width:600px;height:600px;'>\n",
    "#### K = 10 and Regularization = 0.01:\n",
    "<img src='plots/M3_7.png' style='width:600px;height:600px;'>\n",
    "#### K = 50 and Regularization = 0.01:\n",
    "<img src='plots/M3_11.png' style='width:600px;height:600px;'>\n",
    "\n",
    "#### K = 2 and Regularization = 0.1:\n",
    "<img src='plots/M3_4.png' style='width:600px;height:600px;'>\n",
    "#### K = 10 and Regularization = 0.1:\n",
    "<img src='plots/M3_8.png' style='width:600px;height:600px;'>\n",
    "#### K = 50 and Regularization = 0.1:\n",
    "<img src='plots/M3_12.png' style='width:600px;height:600px;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best Performance:**\n",
    "\n",
    "* Train MAE : `0.723`\n",
    "* Valid MAE : `0.753`\n",
    "\n",
    "**Best Params:**\n",
    "\n",
    "* n_factors : `2` , alpha = `0.1`\n",
    "\n",
    "Please check file `M3_4.json` for checking parameter values for this best performing model for this part.\n",
    "\n",
    "After trying various parameters and penalty values we have found out that above mentioned parameter settings give best results.\n",
    "\n",
    "Our current model `M3` performs quite bettern than `M1` and little better than `M2`.We tried various vaues for n_factors like `2, 10, 50` and found out that value of 2 gives best results. Trying more than 50 parameter might not give good results as we have model which give good results for `n_factors = 2` and we tried bigger values than tha like 10,50 which did not give good results than it. Hence we don't recommend trying more than 50 for n_factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Movies Examination\n",
    "We have found out select movies embedding parameters `V` for movies with `K = 2` and `alpha = 0.1`. We'll plot it as scatter plot.\n",
    "\n",
    "We can see that Adventure/Scifi movies(Return of Jedi, Indiana Jones, Star Wars etc) has values which are quite around zero and right in graph.\n",
    "\n",
    "Cartoon/Horror/Animation movies(Lion King, Scream etc) has high positive/negative values for V2 and less value for V1. We can notice that all Adventure/Scifi are gathered around 0 in center and Horror/Cartoon/romantic movies are spread.\n",
    "\n",
    "<img src='select_movies/M3_4.png' style='width:600px;height:600px;'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>release_year</th>\n",
       "      <th>orig_item_id</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>[ 0.55649435 -0.03255801]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>Lion King, The (1994)</td>\n",
       "      <td>1994</td>\n",
       "      <td>71</td>\n",
       "      <td>[-0.23377262  0.44090488]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98</td>\n",
       "      <td>Snow White and the Seven Dwarfs (1937)</td>\n",
       "      <td>1937</td>\n",
       "      <td>99</td>\n",
       "      <td>[ 0.09000491 -0.08183166]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131</td>\n",
       "      <td>Wizard of Oz, The (1939)</td>\n",
       "      <td>1939</td>\n",
       "      <td>132</td>\n",
       "      <td>[ 0.19693762 -0.29926128]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142</td>\n",
       "      <td>Sound of Music, The (1965)</td>\n",
       "      <td>1965</td>\n",
       "      <td>143</td>\n",
       "      <td>[-0.25358477 -0.28140179]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>49</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "      <td>1977</td>\n",
       "      <td>50</td>\n",
       "      <td>[0.10592744 0.05422478]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>171</td>\n",
       "      <td>Empire Strikes Back, The (1980)</td>\n",
       "      <td>1980</td>\n",
       "      <td>172</td>\n",
       "      <td>[ 0.00340893 -0.01312453]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>180</td>\n",
       "      <td>Return of the Jedi (1983)</td>\n",
       "      <td>1997</td>\n",
       "      <td>181</td>\n",
       "      <td>[0.34272096 0.12824491]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>81</td>\n",
       "      <td>Jurassic Park (1993)</td>\n",
       "      <td>1993</td>\n",
       "      <td>82</td>\n",
       "      <td>[-0.43722235 -0.05117469]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>251</td>\n",
       "      <td>Lost World: Jurassic Park, The (1997)</td>\n",
       "      <td>1997</td>\n",
       "      <td>252</td>\n",
       "      <td>[ 0.50879849 -0.46065543]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>173</td>\n",
       "      <td>Raiders of the Lost Ark (1981)</td>\n",
       "      <td>1981</td>\n",
       "      <td>174</td>\n",
       "      <td>[0.23378598 0.01357567]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>209</td>\n",
       "      <td>Indiana Jones and the Last Crusade (1989)</td>\n",
       "      <td>1989</td>\n",
       "      <td>210</td>\n",
       "      <td>[0.60769021 0.11883519]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>65</td>\n",
       "      <td>While You Were Sleeping (1995)</td>\n",
       "      <td>1995</td>\n",
       "      <td>66</td>\n",
       "      <td>[-0.00133896  0.6299172 ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>87</td>\n",
       "      <td>Sleepless in Seattle (1993)</td>\n",
       "      <td>1993</td>\n",
       "      <td>88</td>\n",
       "      <td>[ 0.24953664 -0.22497756]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>254</td>\n",
       "      <td>My Best Friend's Wedding (1997)</td>\n",
       "      <td>1997</td>\n",
       "      <td>255</td>\n",
       "      <td>[-0.74329218 -0.17325982]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>90</td>\n",
       "      <td>Nightmare Before Christmas, The (1993)</td>\n",
       "      <td>1993</td>\n",
       "      <td>91</td>\n",
       "      <td>[-0.24843571  0.27487229]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>199</td>\n",
       "      <td>Shining, The (1980)</td>\n",
       "      <td>1980</td>\n",
       "      <td>200</td>\n",
       "      <td>[-0.1233313   0.27893922]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>218</td>\n",
       "      <td>Nightmare on Elm Street, A (1984)</td>\n",
       "      <td>1984</td>\n",
       "      <td>219</td>\n",
       "      <td>[-0.37194332 -0.59597771]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>286</td>\n",
       "      <td>Scream (1996)</td>\n",
       "      <td>1996</td>\n",
       "      <td>288</td>\n",
       "      <td>[0.02427319 0.42689353]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>893</td>\n",
       "      <td>Scream 2 (1997)</td>\n",
       "      <td>1997</td>\n",
       "      <td>895</td>\n",
       "      <td>[ 0.0161952  -0.55788967]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    item_id                                      title  release_year  \\\n",
       "0         0                           Toy Story (1995)          1995   \n",
       "1        70                      Lion King, The (1994)          1994   \n",
       "2        98     Snow White and the Seven Dwarfs (1937)          1937   \n",
       "3       131                   Wizard of Oz, The (1939)          1939   \n",
       "4       142                 Sound of Music, The (1965)          1965   \n",
       "5        49                           Star Wars (1977)          1977   \n",
       "6       171            Empire Strikes Back, The (1980)          1980   \n",
       "7       180                  Return of the Jedi (1983)          1997   \n",
       "8        81                       Jurassic Park (1993)          1993   \n",
       "9       251      Lost World: Jurassic Park, The (1997)          1997   \n",
       "10      173             Raiders of the Lost Ark (1981)          1981   \n",
       "11      209  Indiana Jones and the Last Crusade (1989)          1989   \n",
       "12       65             While You Were Sleeping (1995)          1995   \n",
       "13       87                Sleepless in Seattle (1993)          1993   \n",
       "14      254            My Best Friend's Wedding (1997)          1997   \n",
       "15       90     Nightmare Before Christmas, The (1993)          1993   \n",
       "16      199                        Shining, The (1980)          1980   \n",
       "17      218          Nightmare on Elm Street, A (1984)          1984   \n",
       "18      286                              Scream (1996)          1996   \n",
       "19      893                            Scream 2 (1997)          1997   \n",
       "\n",
       "    orig_item_id                          V  \n",
       "0              1  [ 0.55649435 -0.03255801]  \n",
       "1             71  [-0.23377262  0.44090488]  \n",
       "2             99  [ 0.09000491 -0.08183166]  \n",
       "3            132  [ 0.19693762 -0.29926128]  \n",
       "4            143  [-0.25358477 -0.28140179]  \n",
       "5             50    [0.10592744 0.05422478]  \n",
       "6            172  [ 0.00340893 -0.01312453]  \n",
       "7            181    [0.34272096 0.12824491]  \n",
       "8             82  [-0.43722235 -0.05117469]  \n",
       "9            252  [ 0.50879849 -0.46065543]  \n",
       "10           174    [0.23378598 0.01357567]  \n",
       "11           210    [0.60769021 0.11883519]  \n",
       "12            66  [-0.00133896  0.6299172 ]  \n",
       "13            88  [ 0.24953664 -0.22497756]  \n",
       "14           255  [-0.74329218 -0.17325982]  \n",
       "15            91  [-0.24843571  0.27487229]  \n",
       "16           200  [-0.1233313   0.27893922]  \n",
       "17           219  [-0.37194332 -0.59597771]  \n",
       "18           288    [0.02427319 0.42689353]  \n",
       "19           895  [ 0.0161952  -0.55788967]  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('select_movies/M3_select_movies_V_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 : Matrix Factorization with surprise\n",
    "We'll try surprise package provided by scikit which provides recommendation algorithms. We'll try SVD and other algorithms doing grid search on its parameters to find best results.\n",
    "\n",
    "We'll first load data according to format of surprise package below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-193-ad9de5f93825>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'user item rating'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_movie_lens_100k/ratings_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_movie_lens_100k/ratings_test_masked.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrainset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_full_trainset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/p3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/p3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/p3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nrows'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/p3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1993\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1995\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1996\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/p3/lib/python3.7/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m     \"\"\"\n\u001b[1;32m    574\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCategorical\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reader = Reader(line_format='user item rating', sep=',')\n",
    "df = pd.read_csv('data_movie_lens_100k/ratings_train.csv')\n",
    "test_df = pd.read_csv('data_movie_lens_100k/ratings_test_masked.csv')\n",
    "data = Dataset.load_from_df(df, reader)\n",
    "trainset = data.build_full_trainset()\n",
    "test_data = Dataset.load_from_df(test_df, reader)\n",
    "#tesstset = test_data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try various values for parameters `n_factors`, regularization parameter `alpha` and `learning rate` to find best solution for our purpose using Grid Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#model_selection.cross_validate(SVD(), data, cv=3, verbose=True)\n",
    "\n",
    "param_grid = {'n_factors': [50,100], 'lr_all': [0.002, 0.005, 0.01],\n",
    "              'reg_all': [0.02, 0.04]}\n",
    "gs_svd = model_selection.GridSearchCV(SVD, param_grid, measures=['mae'], cv=5,\n",
    "                                 n_jobs=-1,joblib_verbose=-1)\n",
    "\n",
    "gs_svd.fit(data)\n",
    "\n",
    "print('Best MAE : ',gs_svd.best_score['mae'])\n",
    "print('Best Params : ',gs_svd.best_params['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_results = pd.DataFrame.from_dict(gs_svd.cv_results)\n",
    "gridsearch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = Dataset.load_from_df(df, reader)\n",
    "trainset, testset = model_selection.train_test_split(data, test_size=.20,random_state=123)\n",
    "svd = SVD(n_factors=50, reg_all =0.04, lr_all=0.01)\n",
    "svd.fit(trainset)\n",
    "\n",
    "predictions = svd.test(testset)\n",
    "\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)\n",
    "\n",
    "preds = np.zeros(len(test_df),dtype=np.float64)\n",
    "for i, (uid,iid) in  enumerate(zip(test_df.user_id,test_df.item_id)):\n",
    "    preds[i] = svd.predict(uid,iid).est\n",
    "\n",
    "np.savetxt(os.path.join('test_preds', \"M4_SVD.txt\"), preds,newline='\\r\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best Performance:**\n",
    "\n",
    "* Train MAE : `0.734`\n",
    "* Valid MAE : `0.734`\n",
    "\n",
    "**Best Params:**\n",
    "\n",
    "* n_factors : `50` , alpha = `0.04`, learning_rate = `0.01`\n",
    "\n",
    "We have found out using SVD that above mentioned parameters best performs using SVD. It's noticeable that `M4` performs bit better than `M3` and `M2` & quite better than `M1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5\n",
    "We'll try various model provided with `surprise` package to see whether there is any performance improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BaseOnly Model with various parameters\n",
    "We are trying 2 optimization methods ALS(Alternating Least Squares) and SGD with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Using ALS')\n",
    "bsl_options = {'method': 'als',\n",
    "               'n_epochs': 15,\n",
    "               'reg_u': 12,\n",
    "               'reg_i': 5\n",
    "               }\n",
    "baseline = BaselineOnly(bsl_options=bsl_options,verbose=False)\n",
    "trainset, testset = model_selection.train_test_split(data, test_size=.20,random_state=123)\n",
    "baseline.fit(trainset)\n",
    "predictions = baseline.test(testset)\n",
    "\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)\n",
    "\n",
    "preds = np.zeros(len(test_df),dtype=np.float64)\n",
    "for i, (uid,iid) in  enumerate(zip(test_df.user_id,test_df.item_id)):\n",
    "    preds[i] = baseline.predict(uid,iid).est\n",
    "\n",
    "np.savetxt(os.path.join('test_preds', \"M5_BASELINE_ONLY.txt\"), preds,newline='\\r\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Using SGD')\n",
    "bsl_options = {'method': 'sgd',\n",
    "               'n_epochs': 10,\n",
    "               'learning_rate': .01,\n",
    "               }\n",
    "baseline = BaselineOnly(bsl_options=bsl_options,verbose=False)\n",
    "trainset, testset = model_selection.train_test_split(data, test_size=.20,random_state=123)\n",
    "baseline.fit(trainset)\n",
    "predictions = baseline.test(testset)\n",
    "\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)\n",
    "\n",
    "preds = np.zeros(len(test_df),dtype=np.float64)\n",
    "for i, (uid,iid) in  enumerate(zip(test_df.user_id,test_df.item_id)):\n",
    "    preds[i] = baseline.predict(uid,iid).est\n",
    "\n",
    "np.savetxt(os.path.join('test_preds', \"M5_BASELINE_ONLY_2.txt\"), preds,newline='\\r\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNNBasic with various parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_options = {'name': 'cosine',\n",
    "               'user_based': False  # compute  similarities between items\n",
    "               }\n",
    "knnbasic = KNNBasic(sim_options=sim_options,verbose=False)\n",
    "trainset, testset = model_selection.train_test_split(data, test_size=.20, random_state=123)\n",
    "knnbasic.fit(trainset)\n",
    "predictions = knnbasic.test(testset)\n",
    "\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)\n",
    "\n",
    "preds = np.zeros(len(test_df),dtype=np.float64)\n",
    "for i, (uid,iid) in  enumerate(zip(test_df.user_id,test_df.item_id)):\n",
    "    preds[i] = knnbasic.predict(uid,iid).est\n",
    "\n",
    "np.savetxt(os.path.join('test_preds', \"M5_KNN_BASIC.txt\"), preds,newline='\\r\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_options = {'name': 'pearson_baseline',\n",
    "               'shrinkage': 0  # no shrinkage\n",
    "               }\n",
    "knnbasic = KNNBasic(sim_options=sim_options, verbose=False)\n",
    "trainset, testset = model_selection.train_test_split(data, test_size=.20, random_state=123)\n",
    "\n",
    "knnbasic.fit(trainset)\n",
    "\n",
    "predictions = knnbasic.test(testset)\n",
    "\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)\n",
    "\n",
    "preds = np.zeros(len(test_df),dtype=np.float64)\n",
    "for i, (uid,iid) in  enumerate(zip(test_df.user_id,test_df.item_id)):\n",
    "    preds[i] = knnbasic.predict(uid,iid).est\n",
    "\n",
    "np.savetxt(os.path.join('test_preds', \"M5_KNN_BASIC_2.txt\"), preds,newline='\\r\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that even after trying various models with various paramters results seem to be not improving much. It seem that we have reached limitation and MAE is not improving further than `0.73`.\n",
    "\n",
    "We tried all above models with Evaluation and training with MAE. It won't make much difference if we use RMSE for training and MAE for evaluation which we can see from above experiments. M4 and M5 are training and evaluation with MAE. M1,M2 and M3 are training with RMSE and evaluation with MAE. We can notice that after certain point MAE is not improving further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "benchmark = []\n",
    "\n",
    "for algorithm in [SVD(), SVDpp(), SlopeOne(), NMF(), NormalPredictor(), KNNBaseline(), KNNBasic(), KNNWithMeans(), KNNWithZScore(), BaselineOnly(), CoClustering()]:\n",
    "    # Perform cross validation\n",
    "    results = model_selection.cross_validate(algorithm, data, measures=['mae'], cv=3, verbose=False)\n",
    "    \n",
    "    # Get results & append algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    benchmark.append(tmp)\n",
    "    \n",
    "pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_mae')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above after trying various models that `SVDpp` performs better than all of them. We'll try it for guessing ratings of test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_factors': [20, 50, 100], 'lr_all': [0.002, 0.007, 0.01],\n",
    "              'reg_all': [0.02, 0.04]}\n",
    "\n",
    "gs_svdpp = model_selection.GridSearchCV(SVD, param_grid, measures=['mae'], cv=5,\n",
    "                                 n_jobs=-1,joblib_verbose=-1)\n",
    "\n",
    "gs_svdpp.fit(data)\n",
    "\n",
    "print('Best MAE : ',gs_svdpp.best_score['mae'])\n",
    "print('Best Params : ',gs_svdpp.best_params['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "svdpp = SVDpp(n_factors = 20, lr_all = 0.01, reg_all = 0.04)\n",
    "trainset, testset = model_selection.train_test_split(data, test_size=.20, random_state=123)\n",
    "\n",
    "svdpp.fit(trainset)\n",
    "\n",
    "predictions = svdpp.test(testset)\n",
    "\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)\n",
    "\n",
    "preds = np.zeros(len(test_df),dtype=np.float64)\n",
    "for i, (uid,iid) in  enumerate(zip(test_df.user_id,test_df.item_id)):\n",
    "    preds[i] = svdpp.predict(uid,iid).est\n",
    "\n",
    "np.savetxt(os.path.join('test_preds', \"M5_SVDPP.txt\"), preds,newline='\\r\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please make a note that SVDpp model has give best result till now with MAE of `0.731`. \n",
    "\n",
    "**Best Performance:**\n",
    "* Train MAE: `0.731`\n",
    "* Test MAE : `0.727`\n",
    "\n",
    "**Best Params:**\n",
    "* n_factors: `20`, alpha: `0.04` , learning rate: `0.02`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6 : Predicting Gender from User Embedding Vectors (U) learned by best M3 model.\n",
    "We'll load User Embedding Vector from our best M3 model and then try to predict user's gender based on this paramters.\n",
    "\n",
    "We have mentioned above that model `M3_4.json` has paramters details for embeddings of best performing model. We also have mentioned that it performed best with `n_factors = 2` and `alpha = 0.1`. We'll load `M3_4.json` into memory and retrieve User Embedding Vector from it which we'll further use to guess user gender.\n",
    "\n",
    "We'll try various scikit-learn models to find out which one performs best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_data = pd.read_csv('data_movie_lens_100k/user_info.csv')\n",
    "\n",
    "params = json.load(open('model_params/M3_4.json'))\n",
    "U = np.array(params['U'])\n",
    "U.shape, users_data.is_male.values.shape\n",
    "X, Y = U, users_data.is_male.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lr = {\n",
    "    'logisticregression__C' : [0.1,1.0,10],\n",
    "    'logisticregression__penalty' : ['l1','l2']\n",
    "}\n",
    "pipeline_lr = make_pipeline(LogisticRegression())\n",
    "\n",
    "grid_lr = GridSearchCV(pipeline_lr, param_grid=params_lr, cv = 5, n_jobs=-1)\n",
    "grid_lr.fit(X, Y)\n",
    "\n",
    "print('Best Score : ',grid_lr.best_score_)\n",
    "print('Best Params : ', grid_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_svc = {\n",
    "    'svc__C' : [0.1,1.0,10],\n",
    "    'svc__gamma' : [0.01,0.1,1.0,10,100, 'auto','scale']\n",
    "}\n",
    "pipeline_svc = make_pipeline(SVC())\n",
    "\n",
    "grid_svc = GridSearchCV(pipeline_svc, param_grid=params_svc, cv = 5, n_jobs=-1)\n",
    "grid_svc.fit(X, Y)\n",
    "\n",
    "print('Best Score : ',grid_svc.best_score_)\n",
    "print('Best Params : ', grid_svc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rf = {\n",
    "    'randomforestclassifier__max_depth' : [None,3,4,5],\n",
    "    'randomforestclassifier__n_estimators' : [100,200,500]\n",
    "}\n",
    "pipeline_rf = make_pipeline(RandomForestClassifier())\n",
    "\n",
    "grid_rf = GridSearchCV(pipeline_rf, param_grid=params_rf, cv = 5, n_jobs=-1)\n",
    "grid_rf.fit(X, Y)\n",
    "\n",
    "print('Best Score : ',grid_rf.best_score_)\n",
    "print('Best Params : ', grid_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_loss(Y, grid_lr.predict(X)))\n",
    "conf_mat = confusion_matrix(Y, grid_lr.predict(X))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_loss(Y, grid_svc.predict(X)))\n",
    "conf_mat = confusion_matrix(Y, grid_svc.predict(X))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_loss(Y, grid_rf.predict(X)))\n",
    "conf_mat = confusion_matrix(Y, grid_rf.predict(X))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that even after trying various good paramters we are not able to get good model whic fits data properly and properly predicts gender. It seems that our best `M3` model does not have enough information to predict gender properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
