{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape Class A - (1000, 40, 60), Class B - (1000, 40, 60), Field - (200, 40, 60)\n"
     ]
    }
   ],
   "source": [
    "class_a = np.load('class_a.npy')\n",
    "class_b = np.load('class_b.npy')\n",
    "field = np.load('field.npy')\n",
    "print('Dataset Shape Class A - %s, Class B - %s, Field - %s'%(str(class_a.shape),str(class_b.shape),str(field.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing First Images from all 3 Files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with plt.style.context(('seaborn', 'ggplot')):\n",
    "    plt.figure(figsize=(15,4))\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(class_a[0])\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(class_b[1])\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(field[1])\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Dataset from 2 classes\n",
    "* Class A - Label 1\n",
    "* Class B - Label 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Dataset :  (2000, 40, 60) (2000,)\n",
      "Combined Dataset :  (2000, 40, 60) (2000,)\n"
     ]
    }
   ],
   "source": [
    "X = np.vstack((class_a,class_b))\n",
    "Y = np.array([1]* len(class_a) + [0]*len(class_b))\n",
    "print('Combined Dataset : ',X.shape,Y.shape)\n",
    "X_sklearn = X.reshape(X.shape[0], -1)\n",
    "print('Combined Dataset : ',X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing Data into Train/Test Sets\n",
    "We have divided dataset with `80%` for training and `20%` for test purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test Sizes :  (1600, 2400) (400, 2400) (1600,) (400,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_sklearn, Y, train_size=0.80, test_size=0.20, stratify=Y, random_state=42)\n",
    "print('Train/Test Sizes : ',X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Training Classifier\n",
    "\n",
    "We'll be tryin 3 different classifiers for our purpose\n",
    "\n",
    "1. Logistic Regression\n",
    "2. Random Forest\n",
    "3. Gradient Boosting\n",
    "\n",
    "### Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=3, n_estimators=50)\n",
    "\n",
    "rf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=2,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=50, max_depth=2)\n",
    "\n",
    "gb.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using Above Model for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 1.000\n",
      "Test Accuracy : 0.998\n"
     ]
    }
   ],
   "source": [
    "print('Train Accuracy : %.3f'%lr.score(X_train, Y_train))\n",
    "print('Test Accuracy : %.3f'%lr.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.994\n",
      "Test Accuracy : 0.998\n"
     ]
    }
   ],
   "source": [
    "print('Train Accuracy : %.3f'%rf.score(X_train, Y_train))\n",
    "print('Test Accuracy : %.3f'%rf.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.999\n",
      "Test Accuracy : 0.995\n"
     ]
    }
   ],
   "source": [
    "print('Train Accuracy : %.3f'%gb.score(X_train, Y_train))\n",
    "print('Test Accuracy : %.3f'%gb.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       200\n",
      "           1       1.00      0.99      1.00       200\n",
      "\n",
      "    accuracy                           1.00       400\n",
      "   macro avg       1.00      1.00      1.00       400\n",
      "weighted avg       1.00      1.00      1.00       400\n",
      "\n",
      "\n",
      "Confusion Matrix : \n",
      "[[200   0]\n",
      " [  1 199]]\n"
     ]
    }
   ],
   "source": [
    "print('\\nClassification Report : ')\n",
    "print(classification_report(Y_test, lr.predict(X_test)))\n",
    "\n",
    "print('\\nConfusion Matrix : ')\n",
    "print(confusion_matrix(Y_test, lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       200\n",
      "           1       1.00      0.99      1.00       200\n",
      "\n",
      "    accuracy                           1.00       400\n",
      "   macro avg       1.00      1.00      1.00       400\n",
      "weighted avg       1.00      1.00      1.00       400\n",
      "\n",
      "\n",
      "Confusion Matrix : \n",
      "[[200   0]\n",
      " [  1 199]]\n"
     ]
    }
   ],
   "source": [
    "print('\\nClassification Report : ')\n",
    "print(classification_report(Y_test, rf.predict(X_test)))\n",
    "\n",
    "print('\\nConfusion Matrix : ')\n",
    "print(confusion_matrix(Y_test, rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       200\n",
      "           1       1.00      0.99      0.99       200\n",
      "\n",
      "    accuracy                           0.99       400\n",
      "   macro avg       1.00      0.99      0.99       400\n",
      "weighted avg       1.00      0.99      0.99       400\n",
      "\n",
      "\n",
      "Confusion Matrix : \n",
      "[[200   0]\n",
      " [  2 198]]\n"
     ]
    }
   ],
   "source": [
    "print('\\nClassification Report : ')\n",
    "print(classification_report(Y_test, gb.predict(X_test)))\n",
    "\n",
    "print('\\nConfusion Matrix : ')\n",
    "print(confusion_matrix(Y_test,gb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions On Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2400)\n"
     ]
    }
   ],
   "source": [
    "Z = field.reshape(field.shape[0],-1)\n",
    "print(Z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0632051  0.9367949 ]\n",
      " [0.06827602 0.93172398]\n",
      " [0.82719413 0.17280587]]\n",
      "[[0.0632051  0.9367949 ]\n",
      " [0.06827602 0.93172398]\n",
      " [0.82719413 0.17280587]]\n"
     ]
    }
   ],
   "source": [
    "lr_preds = lr.predict_proba(Z)\n",
    "print(lr_preds[:3])\n",
    "\n",
    "\n",
    "np.savetxt('logistic_regresion_class_preds.txt', np.array(['A' if pred==1 else 'B' for pred in lr.predict(Z)]), '%s')\n",
    "np.save('logistic_regression_preds.npy', lr_preds)\n",
    "\n",
    "lr_preds_reload = np.load('logistic_regression_preds.npy')\n",
    "print(lr_preds_reload[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.47328328 0.52671672]\n",
      " [0.52143465 0.47856535]\n",
      " [0.55687731 0.44312269]]\n",
      "[[0.47328328 0.52671672]\n",
      " [0.52143465 0.47856535]\n",
      " [0.55687731 0.44312269]]\n"
     ]
    }
   ],
   "source": [
    "rf_preds = rf.predict_proba(Z)\n",
    "print(rf_preds[:3])\n",
    "\n",
    "\n",
    "np.savetxt('random_forest_class_preds.txt', np.array(['A' if pred==1 else 'B' for pred in rf.predict(Z)]), '%s')\n",
    "np.save('random_forest_preds.npy', rf_preds)\n",
    "\n",
    "rf_preds_reload = np.load('random_forest_preds.npy')\n",
    "print(rf_preds_reload[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5590884  0.4409116 ]\n",
      " [0.49012807 0.50987193]\n",
      " [0.54644002 0.45355998]]\n",
      "[[0.5590884  0.4409116 ]\n",
      " [0.49012807 0.50987193]\n",
      " [0.54644002 0.45355998]]\n"
     ]
    }
   ],
   "source": [
    "gb_preds = gb.predict_proba(Z)\n",
    "print(gb_preds[:3])\n",
    "\n",
    "\n",
    "np.savetxt('gradient_boosting_class_preds.txt', np.array(['A' if pred==1 else 'B' for pred in gb.predict(Z)]), '%s')\n",
    "np.save('gradient_boosting_preds.npy', gb_preds)\n",
    "\n",
    "gb_preds_reload = np.load('gradient_boosting_preds.npy')\n",
    "print(gb_preds_reload[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
